% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage[hyphens]{url} % not crucial - just used below for the URL
\usepackage{hyperref}
\usepackage{listings} 
\usepackage{booktabs}
\usepackage{float}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[onehalfspacing]{setspace}
\usepackage[usenames,dvipsnames]{color}    
\usepackage[font=small, font+=singlespacing,labelfont=bf]{caption}

\lstset{ 
  language=R,                     % the language of the code
  basicstyle=\scriptsize\ttfamily,      % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\scriptsize\color{Blue},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it is 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  keywordstyle=\color{RoyalBlue},      % keyword style
  commentstyle=\color{YellowGreen},   % comment style
  stringstyle=\color{ForestGreen}      % string literal style
}
 
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

%% load any required packages here

\makeatletter
\newcommand*{\centerfloat}{%
  \parindent \z@
  \leftskip \z@ \@plus 1fil \@minus \textwidth
  \rightskip\leftskip
  \parfillskip \z@skip}
\makeatother

\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf Testing for Complementarities between Accounting Practices}

  \author{
        Stijn Masschelein \thanks{The authors are grateful for comments by David Bedford, seminar participants at Leuven University, Australian National University, the University of Technology Sydney, the University of New South Wales, and the University of Western Australia, the 2018 AFAANZ conference, and the 2018 AOS conference on Management Control as System or Package in Maastricht.} \\
    University of Western Australia Business School\\
     and \\     Frank Moers \\
    Maastricht University School of Business and Economics\\
      }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Statistical Methods for Accounting Systems}
  \end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Following the theoretical innovations of complementarity theory, management control studies have investigated  interdependencies between management control practices. In this paper, we compare the two dominant statistical specifications to test for the presence of an interdependency. We show theoretically how the power of the demand and the performance specification varies with the level of optimality in the sample and how those specifications are vulnerable to correlated omitted variable bias. Our simulation results reveal that the demand specification is more robust to variations in optimality and correlated omitted variables than the performance specification. We use these results to formulate guidance for future research into management control interdependencies.
\end{abstract}

\noindent%
{\it Keywords:} Complementarity Theory, Management Control, Statistical Methods
\vfill

\newpage

\spacingset{1.15}

\section{Introduction}\label{introduction}

The management accounting literature has investigated firms' choices of interdependent practices such as delegation and incentives \citep{bouwens_assessing_2007, indjejikian_accounting_2012, moers_performance_2006}, or the levers of control \citep{simons_levers_1994, simons_performance_2000, widener_empirical_2007}, and devoted considerable attention to investigating the fit between the practices and the firms' environment \citep{chenhall_management_2003, otley_contingency_2016}. The interdependencies between practices are the reason a collection of practices form an accounting system  \citep{grabner_management_2013,milgrom_complementarities_1995}. When two practices positively reinforce or complement each other, the firm benefits from using them together, as a system. When two practices negatively reinforce each other, they act as substitutes. In this paper, we compare the two most common specifications in the empirical literature to test whether practices are complements (or substitutes), i.e., the performance specification and the demand specification \citep{grabner_management_2013}, and examine the vulnerability of these specifications to their underlying assumptions. 

The performance specification tests whether the interaction between two practices is postively correlated with performance \citep{athey_empirical_1998, carree_note_2011, grabner_management_2013, hofmann_organizational_2017}. For instance, the interaction between delegation and accounting based incentives is positively related to business unit performance. The performance specification assumes that there are a "sufficient number" of firms that deviate from the optimal choices which allows researchers to detect performance differences between optimal and suboptimal accounting systems. The extreme version of this assumption is that all firms make random choices. The demand specification tests whether two practices are positively correlated with each other after controlling for environmental factors \citep{arora_testing_1996, grabner_management_2013, johansson_testing_2018, hofmann_organizational_2017}.  For instance, delegation and accounting based incentives are correlated after controlling for environmental factors. The demand specification assumes that there are a "sufficient number" of firms that simultaneously choose the optimal level of the practices taking into account the interdependency and the firm's environment. The extreme version of this assumption is that all firms make optimal choices.

In observational samples neither the assumption of completely randomly chosen practices nor the assumption of completely optimal choices will hold \citep{brynjolfsson_complementarity_2013}. While an individual decision is either optimal or not, a sample of those individual decisions can exhibit different levels of optimality. That is, different samples can contain different proportions of optimal decisions. The methodology literature has treated the assumption about the level of optimality in a sample as an untestable assumption and recommends that researchers argue whether their chosen specification is appropriate for their research setting. The demand specification is often seen as more appropriate than the performance specification when one decision maker has designed the entire accounting system, when the optimal design is not too complicated, and when the decision maker has had sufficient time and incentives to choose the optimal system \citep{grabner_management_2013, hofmann_organizational_2017, carree_note_2011, johansson_testing_2018}.  The performance specification is often deemed more appropriate when it involves relatively new practices and technologies that require experimentation \citep{carree_note_2011, bedford_management_2016}. While this recommendation is intuitive, its empirical validity is not clear. That is, it is not clear how vulnerable each specification is to deviations from its underlying assumption of (lack of) optimality and whether this vulnerability differs between the two specifications. The key question we address in this paper is whether the typical arguments for choosing a specification are necessary and/or sufficient.

In addressing this question, we first show how the demand and performance specification arise from the same underlying and unobserved objective function. The objective function formalises the performance effects of management accounting practices and how those performance effects depend on other practices and contingency factors. As a result, the objective function captures the main insight of complementarity theory \citep{milgrom_complementarities_1995,grabner_management_2013} and contingency theory \citep{chenhall_management_2003,otley_contingency_2016} and is thus the theoretical foundation for hypothesis development regarding interdependencies. We then show the statistical problems that arise with the demand and performance specification when the assumptions underlying these specifications are not satisfied. First, the demand specification has more power to detect an interdependency when management control practices are closer to optimal while the performance specification is more likely to detect an interdependency when the control practices are further from optimal. But again, how close to or how far from optimal the practices need to be to have sufficient power is an open question. Second, while the omitted variable problem is widely recognised for the demand specification \citep{grabner_management_2013, arora_testing_1996, hofmann_organizational_2017}, it is largely ignored \citep{grabner_management_2013, hofmann_organizational_2017} or thought of as non-existing for the performance specification \citep{carree_note_2011}. We show that both specifications are vulnerable to the same omitted variable bias when they do not appropriately control for a contingency factor that affects both practices. When all relevant practices and contingency factors are observed, this bias can be easily addressed, although the most commonly used variant of the performance specification unfortunately does not address the bias. Furthermore, it is an open question whether the specifications are equally vulnerable to correlated omitted variables.

To investigate the robustness of both specifications to variations in the level of optimality, we use a simulation. In doing this, we focus on Type I errors (rejection of a true null hypothesis of no complementarity) and power (or Type II errors, i.e., failure to reject a false null hypothesis of no complementarity). The results show that the demand specification has appropriate type I error rates while maintaining power to detect a real complementary effect even at low levels of optimality. In contrast, the theoretically derived performance specification suffers from elevated type I error rates at all levels of optimality and loses power to detect true interdependencies at higher levels of optimality. In addition, the performance specification as it is typically implemented in the literature is biased when the practices are contingent on the same environmental factor. Finally, in contrast to common belief, even in the presence of correlated omitted variables, the demand specification fares better than the performance specification.

This study contributes to the literature by providing three recommendations for studies that test for interdependencies between management control practices. First of all, the demand specification is generally preferred over the performance specification in an observational sample of firms. While researchers are typically recommended to argue whether their chosen specification is appropriate for their research setting, our findings indicate that the use of the performance specification needs to be especially well-substantiated. Even when performance data is available, it is still advisable to report the demand functions before reporting the performance specification \citep{aral_three-way_2012, cassiman_search_2006}. Second, when theory and prior research indicate that the practices are contingent on environmental factors, studies should appropriately control for these factors. Because the management control literature has a rich history of studying contingency effects, we believe most management control settings will warrant appropriate controls for environmental factors. Importantly, these controls are as relevant for the performance specification as they are for the demand specification. In the demand specification, controlling for contingency factors means including the contingency variables as separate independent variables. In the performance specification, controlling for contingency effects requires including the interaction of the contingency factors with the management control practices. Of the published studies using the performance specification following \citet{grabner_management_2013}, only \citet{bedford_management_2016, bedford_performance_2019} appropriately control for contingency factors. Third, because the performance specification is vulnerable to Type I errors, we advise to use more robust estimation techniques than ordinary least squares.

The remainder of this paper is structured as follows. First, we derive the demand and performance specifications from a common objective function. Second, we explain and calibrate the simulation approach. Third, we compare the robustness of the different specifications in a simulation study. Fourth, we provide guidance for researchers who estimate interdependencies. Last, we summarise the simulation results and guidance, and discuss how future research can further the estimation of interdependencies.

\section{Model and formal analysis}\label{model-and-formal-analysis}

In this section, we present a firm's objective function that encapsulates the essential elements of both complementarity theory and contingency theory. Following complementarity theory, the performance of management control practices can be interdependent. Following contingency theory, the performance effects of the practices depend on the environment. The theoretical model helps to make the assumptions in the two statistical specifications explicit. We assume that a firm has to decide on the level of two management accounting practices which depend on one environmental factor. We represent the levels of the management accounting practices as  $x_1$ and $x_2$ and the level of the environmental factors as $z$. We further assume that the performance, $y$, depends on a factor $\nu$ while the performance effects of each management control practices further depends on a factor $\epsilon_1$ and $\epsilon_2$ respectively. That is, there is variation among firms in the extent to which each management control practice separately affects performance. $x_1$, $x_2$ and $z$ are observed by the researcher but $\epsilon_1$, $\epsilon_2$, and $\nu$ are not. 

We apply the model to the management accounting literature where $z$ stands for environmental uncertainty, the most commonly studied environmental factor in the contingency literature. $x_1$ and $x_2$ are two commonly studied management control decisions, the extent to which decisions are delegated to middle level managers (henceforth delegation) and the extent to which accounting measures are used to evaluate and reward performance of the middle level managers (henceforth accounting incentives). Finally, $y$ is the financial performance of the business unit. These four constructs have received considerable attention in both the contingency and the complementarity literature \citep{grabner_management_2013,chenhall_management_2003, otley_contingency_2016}. In the example, we cannot do justice to the rich theories and measurement developed in the literature and therefore the example should only be seen as an illustration of the objective function. In addition, the linear form is a special case, but its simplicity allows us to make our point without loss of generality.

\begin{equation}\label{eq:objective}
y  = \beta_0 + (\beta_{11} + \gamma_1 z + \epsilon_1) x_1 
						+ (\beta_{22} + \gamma_2 z  + \epsilon_2) x_2 
                        + \beta_{12} x_1 x_2 - \frac{1}{2}\delta_1 x^2_1 - \frac{1}{2}\delta_2 x^2_2 + \nu
\end{equation}
The objective function \eqref{eq:objective} shows how profit, $y$, depends on delegation and accounting incentives, $x_1$ and $x_2$, environmental uncertainty $z$ and the unobservable factors. The parameter $\beta_{12}$ represents the complementarity between delegation and accounting incentives (i.e. $\frac{\delta^2 y}{\delta x_1 \delta x_2} = \beta_{12}$, see \citet{grabner_management_2013}). Irrespective of which empirical test will be performed, interdependence implies that $\beta_{12}\neq0$ and this is what needs to be theoretically substantiated. In this paper, we focus on specifications to test the hypothesis that $\beta_{12} \neq 0$.\footnote{We limit the paper to two-way complementarities for two reasons. First, theory in management control typically does not predict higher order interdependencies (for an exception outside of management accounting see \citet{aral_three-way_2012}). Second, the paper's main focus is on the consequences of deviations from completely optimal and completely random practices for hypotheses tests. The problems we identify apply to more complex hypothesis tests for higher order interdependencies. For simplicity, we avoid the additional complications of testing for higher order interdependencies \citep{carree_note_2011}. For similar reasons, we do not consider contingency effects on the interdependencies \citep{grabner_incentive_2014, grabner_cost_2016, matejka_balancing_2017}.}
For instance, whether the effectiveness of incentive contracts depends on the level of delegation for managers \citep{moers_performance_2006, indjejikian_accounting_2012}. The parameters $\gamma_1$ and $\gamma_2$ represent the contingency effect of environmental uncertainty, $z$, for delegation, $x_1$, and accounting incentives, $x_2$. For instance, $\gamma_1 > 0$ implies that delegation is more valuable for the firm with higher environmental uncertainty while $\gamma_2 < 0$ implies that accounting incentives are less valuable with higher environmental uncertainty \citep{chenhall_management_2003}. 
$\delta_1$ and $\delta_2$, which we assume to be positive, represent increasing marginal costs to the practices.\footnote{$\delta_{1}$ and $\delta_{2}$ are the second derivatives of the performance effects of the practices. In general, $\mathbf{\delta} > 0$ is a mathematical representation of decreasing marginal returns,  increasing marginal  costs, or a combination of both. For simplicity and in line with the specification in \citet{grabner_management_2013}, we interpret $\mathbf{\delta}$ as the parameter of  increasing marginal costs.} 

The objective function \eqref{eq:objective} formalises management accounting theory. The key assumptions of complementarity theory and contingency theory are captured by the parameters $\beta_{12}$ and $\gamma_1, \gamma_2$ respectively. In order to test for a complementarity between delegation and accounting incentives, we need to make additional assumptions about the statistical model, which we will discuss below. The theoretical assumptions discussed above and the statistical assumptions discussed below are the same for both the demand specification and the performance specification.

We assume that $\epsilon_1$ and $\epsilon_2$ and $\nu$ are independent which implies that the model contains all contingency variables and all practices that affect the performance of the two practices $x_1$ and $x_2$. The objective function \eqref{eq:objective} is similar to the the objective function in \citet{kretschmer_competitive_2012} with two exceptions. First, we assume that the values of $x_1$ and $x_2$ are continuous while \citet{kretschmer_competitive_2012} allow for binary practices. We return to the issue of binary practices as an extension to the current model. Second, we assume independence of the unobserved factors. We will relax this assumption, when we introduce the problem of correlated omitted variables further in this section.\footnote{\citet{athey_empirical_1998} discuss the implications of relaxing the independence assumption in more detail.}  In the remainder of this section, we will work with the simple objective function with two practices and one environmental factor. 

\subsection{Optimal level of practices} \label{optimal-level-of-practices}

Profit maximising firms try to adopt the optimal level for each practice. As a benchmark, we derive the optimal level for all practices by setting the first derivative of the objective function \eqref{eq:objective} to each practice equal to $0$ and then solve for each practice, which results in:

\begin{equation}\label{eq:optimal}
\begin{aligned}
x_1^* &= \frac{\beta_{11} + \gamma_1 z + \beta_{12} x_2^*  + \epsilon_{1}}{\delta_1 }
		      = \frac{\delta_2 (\beta_{11} + \gamma_1 z + \epsilon_1) 
           					+ \beta_{12} (\beta_{22} + \gamma_2 z + \epsilon_2) }
                            {\delta_1 \delta_2 - \beta_{12}^2} \\
 x_2^* &= \frac{\beta_{22} + \gamma_2 z + \beta_{12} x_1^* + \epsilon_{2}}{\delta_2  }
		      =  \frac{\delta_1 (\beta_{22} + \gamma_2 z + \epsilon_2) 
           					+ \beta_{12} (\beta_{11} + \gamma_1 z + \epsilon_1) }
                            {\delta_1 \delta_2 - \beta_{12}^2} \\
\end{aligned}
\end{equation}
A number of conclusions can be drawn from the optimality conditions \eqref{eq:optimal}. First, in the absence of complementarity ($\beta_{12}=0$), the optimal level of delegation, $\mathbf{x^*_1}$ and the optimal level of accounting incentives, $\mathbf{x^*_2}$ are still correlated. The contingency effects of environmental uncertainty introduce a relation between the optimal level of delegation, $\mathbf{x^*_1}$, the optimal level of accounting incentives, $\mathbf{x^*_2}$ and environmental uncertainty, $z$. Second, in the absence of a complementarity ($\beta_{12} = 0$) and after controlling for environmental uncertainty, there is no relation between the optimal level of delegation and accounting incentives, i.e. the conditional correlation, $cor(x^*_1 | z, x^*_2 |z) = 0$.  In contrast, in the presence of a complementarity, $\beta_{12} > 0$, the optimal level of delegation positively correlates with the optimal level of accounting incentives after controlling for $\mathbf{z}$. 

We define $r_{12}$, $r_{1z}$, and $r_{2z}$ as the observed sample correlations between delegation, $\mathbf{x_1}$, and accounting incentives, $\mathbf{x_2}$,  between delegation, $\mathbf{x_1}$, and environmental uncertainty, $\mathbf{z}$, and between accounting incentives, $\mathbf{x_2}$, and environmental uncertainty, $\mathbf{z}$, respectively. In samples with higher levels of optimality, the observed correlations are determined by the equations \eqref{eq:optimal}.  In samples where management control practices are randomly chosen, the correlations are $0$. 

Finally, the second order condition for the optimality conditions \eqref{eq:optimal} equals $\delta_1 \delta_2 - \beta_{12}^2 > 0$. The intuition behind this condition is that the increase in marginal costs to delegation and accounting incentives needs to be relatively large so that the interdependency does not dominate the optimal solution. That is, it avoids corner solutions where management control practices are either optimally used to their full extent or not at all.\footnote{In the main analysis of this paper, we will assume that the second-order condition holds when the control practices are continuous. In Section 4.4 we relax this assumption.}

\subsection{Performance Specification}

The performance function approach to examine complementarity estimates the objective function \eqref{eq:objective} directly. In essence, the stochastic form of function \eqref{eq:objective} is a regression equation. With cross-sectional data, the closest approximation to the objective function is the first of the following three regression models.  

\begin{align*}
\mathbf{y} &=  \beta^{p1}_0 + (\beta^{p1}_{11} + \gamma_1^{p1} \mathbf{z} )\mathbf{x_1} 
						+ (\beta_{22}^{p1} + \gamma_2 \mathbf{z} ) \mathbf{x_2} 
                        + \beta_{12}^{p1} \mathbf{x_1} \mathbf{x_2} 
                        + \delta_1^{p1} \mathbf{x^2_1} + \delta_2^{p1} \mathbf{x^2_2} 
                        + \alpha^{p1} \mathbf{z}
                        + \nu^{p1} \\
 \mathbf{y} &=  \beta^{p2}_0 + (\beta^{p2}_{11} + \gamma_1^{p2} \mathbf{z} )\mathbf{x_1} 
						+ (\beta_{22}^{p2} + \gamma_2 \mathbf{z} ) \mathbf{x_2} 
                        + \beta_{12}^{p2} \mathbf{x_1} \mathbf{x_2} 
                        + \alpha^{p2} \mathbf{z}
                        + \nu^{p2} \\
 \mathbf{y} &=  \beta^{p3}_0 + \beta^{p3}_{11} \mathbf{x_1} 
						+ \beta_{22}^{p3} \mathbf{x_2} 
                        + \beta_{12}^{p3} \mathbf{x_1} \mathbf{x_2} 
                        + \alpha^{p3} \mathbf{z}
                        + \nu^{p3}
\end{align*}
The first specification captures all features of the objective function \eqref{eq:objective} with the exception of the unobservable contingency effects on delegation and accounting incentives, $\epsilon_1$ and $\epsilon_2$. Cross-sectional data does not permit estimating the unobservable heterogeneity. In this specification, \(\beta_{12}^{p1}\) tests for the interdependency between the management accounting practices. We are not aware of any accounting studies using this specification, which we label the \emph{performance 1} specification. 

The second specification, which we label the \emph{performance 2} specification, is the correct specification for binary practices, i.e., when practices are either absent or present. In that case, the quadratic terms, $x_i^2$, automatically drop out of the equation. While investigating continuous practices, \citet{ bedford_management_2016, bedford_performance_2019} follow this specification as they control appropriately for contingency factors and drop the quadratic terms in the specification. The majority of the literature follows the third performance specification, which also drops the controls for the contingency factors or assumes that $\gamma_1 = \gamma_1 = 0$. This specification thus ignores the insights from contingency theory. We call this specification \emph{performance 3}. In the remainder of this section, we explain the potential problems with these three specifications.

\subsubsection{Lack of Power}

All three specifications will suffer form the well known problem that performance is no longer a function of the management practices when firms optimally adopt interdependent practices \citep{grabner_management_2013}. This can be illustrated using objective function \eqref{eq:objective} and the optimality conditions \eqref{eq:optimal}. When we set $x_1 = x_1^*$ and $x_2 = x_2^*$ in the objective function  \eqref{eq:objective}, i.e., the firm makes optimal decisions, we find that profit, $y$, is fully determined by the unknown parameters and environmental uncertainty, $z$, and profit no longer depends on the value of the practices. Thus, \textit{observed} profit is not a function of \textit{observed} delegation and accounting incentives when all firms adopt the optimal system. With optimal levels of delegation and accounting incentives, business unit profit is only a function of environmental uncertainty. There is no longer information about the practices in the performance variable. This is what economists are referring to when they say that one cannot examine performance effects of choices. The point is not that there are no performance effects of adopting management control practices, but rather that such effects cannot be empirically detected. 

The loss of power of the performance specification depends on the level of optimality in the sample. A higher level of optimality leads to stronger  correlations between the control practices and the contingency factor, and less independent information in the \textit{observed} practices about the \textit{observed} profit. For a performance specification to have sufficient power, there needs to be a sufficient number of firms that are not adopting the optimal level of the practices \citep{bedford_management_2016, carree_note_2011, hofmann_organizational_2017}. However, the literature has not gone beyond this rule of thumb and provides no guidance on how large the deviations from optimality need to be. Our simulation study will provide an answer to this question.

\subsubsection{Correlated Omitted Variable}

In this paper, we identify a second problem with the most popular specification in the literature, \emph{performance 3}, which follows directly from the contingency effects. The specification omits the terms $\mathbf{x_1 z}$, $\mathbf{x_2 z}$, $\mathbf{x_1^2}$, and $\mathbf{x_2^2}$. Although a full treatment of the omitted variable bias is beyond the scope of this study, we illustrate the problem for the special case where $\mathbf{x_1}$, $\mathbf{x_2}$, and $\mathbf{z}$ follow a multivariate standard normal distribution. Appendix \ref{appendix-omitted} shows that the bias for omitting $\mathbf{x_1 z}$, $\mathbf{x_2 z}$, $\mathbf{x_1^2}$, and $\mathbf{x_2^2}$ in the estimate $\beta^{p3}_{12}$ is proportional to the following components:

\begin{equation}\label{eq:omitted}
\begin{aligned}
\gamma_1 \frac{cov(\mathbf{x_1 x_2}, \mathbf{x_1 z})}{var(\mathbf{x_1 z})} &= 
\gamma_1 \frac{r_{2z} + r_{12} r_{1z}}{1 + r_{1z}^2}
&\gamma_2 \frac{cov(\mathbf{x_1 x_2}, \mathbf{x_2 z})}{var(\mathbf{x_2 z})} &= 
\gamma_2 \frac{r_{1z} + r_{12} r_{2z}}{1 + r_{2z}^2}
\\
\delta_1 \frac{cov(\mathbf{x_1 x_2}, \mathbf{x_1^2})}{var(\mathbf{x_1^2})} &= 
\delta_1 r_{12}
&\delta_2 \frac{cov(\mathbf{x_1 x_2}, \mathbf{x_2^2})}{var(\mathbf{x_2^2})} &= 
\delta_2 r_{12}
\end{aligned}
\end{equation}
where $r_{12}$, $r_{1z}$, and $r_{2z}$ are the observed sample correlations, as defined before. Let's assume that there is no interdependency, i.e., $\beta_{12}=0$. The estimate $\beta^{p3}_{12}$ , which equals $\beta_{12} + bias$, is then affected by the four components specified in \eqref{eq:omitted}. $\beta^{p3}_{12}=\beta_{12}=0$ when the observed correlations $r_{12}$, $r_{1z}$, and $r_{2z}$ are all zero, or in other words, when firms just randomly pick their management control practices. However, as explained in the previous section, contingency theory implies that those empirical correlations between delegation, accounting incentives, and environmental uncertainty are different from $0$ when firms are not completely ignorant of the optimal levels. As a result, when environmental uncertainty is not appropriately controlled for, the \emph{performance 3} specification is vulnerable to an omitted variable bias when testing for a complementarity between delegation and accounting incentives. The intuition behind the bias is as follows. If delegation, $\mathbf{x_1}$, and environmental uncertainty, $\mathbf{z}$, are correlated, the interaction between delegation and accounting incentives, $\mathbf{x_1 x_2}$, and the interaction between accounting incentives and environmental uncertainty, $\mathbf{x_2 z}$, are also correlated. As a result, when the contingency effect, $\mathbf{x_1 z}$, is omitted from the performance specification, the complementarity test, $\mathbf{x_1 x_2}$, will pick up the contingency effect, even when $\beta_{12}=0$. That is, a Type I error occurs. Note that this problem extends to the \emph{performance 1} and \emph{performance 2} specifications when factors unobservable to the researcher affect both practices, which we will address later.

Because the bias does not require perfectly optimal decisions and follows directly from the contingency effect of environmental uncertainty on delegation ($\gamma_1 \neq 0$) and accounting incentives ($\gamma_2 \neq 0$), this problem cannot be easily ignored in a typical management accounting study. A special case of the omitted variable bias is the omission of the quadratic terms $\delta_1 \mathbf{x_1}^2$ and $\delta_2 \mathbf{x_2}^2$, like in \emph{performance 2}. Omission of these terms will bias the estimate of the $\beta^{p2}_{12}$ with a factor proportional to the correlation between delegation and incentives.

The empirical and methodology literature has focused on this bias in the demand specification (see also section \ref{demand-specification}) but has largely ignored the problem of correlated omitted environmental factors in performance specifications. We showed that the performance specifications suffer from the exact same bias in contrast to what has been argued in the methodology literature \citep{carree_note_2011}. 

\subsection{Demand Specification}\label{demand-specification}

The \emph{demand specification} can take two forms, the regression approach and the conditional correlation approach. The first approach regresses one practice (e.g. delegation) on the other (e.g. accounting incentives) and controls for environmental uncertainty.
\begin{equation*} 
\mathbf{x_1} = \beta_0^d + \beta_{12}^d \mathbf{x_2} 
        + \gamma_{1}^d \mathbf{z}
        + \mathbf{\epsilon^d}
\end{equation*}
The regression specification approximates the optimality condition \eqref{eq:optimal} where \(\beta^d_{12}\) is the parameter that estimates the complementarity effect. An alternative and equivalent approach is to estimate the conditional correlation between delegation and incentives. Prior research has used seemingly unrelated regressions with $x_1$ and $x_2$ as dependent variables or seperate OLS regressions to condition on environmental practices \citep{indjejikian_accounting_2012, matejka_balancing_2017}.\footnote{The equivalence between the regression and the conditional correlation follows from the regression anatomy. That is, $\beta^d_{12}=\frac{cov(\mathbf{x_1}, \mathbf{x_2|z)}}{var (\mathbf{x_2|z})}=\frac{cov(\mathbf{x_1|z}, \mathbf{x_2|z)}}{var (\mathbf{x_2|z})}=cor(\mathbf{x_1|z}, \mathbf{x_2|z)}\frac{stdev(\mathbf{x_1|z})}{stdev (\mathbf{x_2|z})}$. Thus, $\beta^d_{12}$ is proportional to the conditional correlation $cor(\mathbf{x_1|z}, \mathbf{x_2|z})$.} In the remainder of this section, we will explain the problems with the demand specification from the perspective of the regression approach. Those problems equally apply to the conditional correlation approach.  

\subsubsection{Lack of Power}

When $\beta_{12} \neq0$ but firms do not take these interdependencies and the contingency effects into account, the empirical correlations are expected to be 0 and so does the regression estimate $\beta_{12}^d$. In the remainder of this study, we consider this an unreasonable assumption unless researchers can identify a natural experiment for the adoption of the practices, $x_1$ and $x_2$. In the simulation study, we will investigate what happens when we vary the extent to which firms adopt the optimal level of delegation and accounting incentives. When firms' accounting systems deviate strongly form the optimal accounting system, the empirical correlations will be small and the demand specification will lack power to detect a real interdependency.

\subsubsection{Correlated Omitted Variable}

The omitted variable bias for the demand function is a well known problem \citep{arora_testing_1996,grabner_management_2013,hofmann_organizational_2017}. When testing for the complementarity between delegation and accounting incentives without controlling for environmental uncertainty, the estimate of the interdependency ($E[\beta_{12}^d]$) will be biased. That is, $E[\beta_{12}^d]=\beta_{12}^d+\gamma_{1}^d \frac{cov(\mathbf{z}, \mathbf{x_2})}{var(\mathbf{x_2})}$. For instance, if environmental uncertainty is positively associated with delegation ($\gamma_{1}^d>0$) and negatively with accounting incentives ($cov(\mathbf{z}, \mathbf{x_2})<0$), $E[\beta_{12}]$ might be negative even in the presence of a complementarity between delegation and accounting incentives, i.e., $\beta_{12}^d>0$. Hence, the demand specification needs to control for environmental uncertainty. Similarly, a researcher has to control for all other contingency factors that effect both delegation and incentives.

\subsection{Summary}

A researcher's decision to use a performance specification or a demand specification is often framed as a trade-off between the lack of power of the demand specification when the practices are far from the optimal levels and the lack of power of the performance specification when the practices are close to the optimal levels \citep{grabner_management_2013, aral_three-way_2012,johansson_testing_2018}. While our analysis confirms this trade-off, the key question that remains, is at what levels of optimality one method dominates the other one. For example, how far from the optimal levels should firm choices be before the performance specification has more power than the demand specification and is thus preferred?

An additional decision rule by researchers seems to be the correlated omitted variable problem. The correlated omitted variable bias of the demand specification is a well known problem \citep{grabner_management_2013,arora_testing_1996,carree_note_2011}, which would suggest a preference for the performance specification when such omitted variables are expected to be present. However, the importance of this section is that it highlights the often ignored omitted variable bias in the performance specification. We show that both specifications are vulnerable to the same omitted variable bias. That is, both specification will be biased if they do not control appropriately for an environmental factor that is a contingency factor for both practices of interest and when firms (to some extent) take into account these contingencies when they design their accounting system. A second question is therefore: \emph{how} vulnerable is each method to correlated omitted variables? To address these two question, we perform a simulation study.

\section{Simulation Study}\label{simulation-study}

In the simulation study that follows, we investigate the three performance specifications and the demand specification with respect to: (1) Type I errors, i.e., incorrectly rejecting a true null-hypothesis; and (2) power, i.e., the ability to reject a false null-hypothesis. Our main analysis focuses on the key question and examines how the level of optimality affects Type I errors and power of the theoretically appropriate \emph{demand} and \emph{performance 1} specifications, as well as how these compare to the \emph{performance 2} and \emph{performance 3} specification that researchers have used to test for the complementarity between management accounting practices.  

Following the main analysis, we test the robustness of the findings to variations in the parameters of the objective function \eqref{eq:objective}. In addition, we investigate to what extent the demand specification is vulnerable to a violation of the second order optimality condition and whether the properties of the specifications change with binary practices. Lastly, we investigate to what extent the theoretically appropriate \emph{demand} and \emph{performance 1} specification are vulnerable to omitted correlated variables. 

\subsection{Simulation Algorithm}

In this section, we describe the simulation algorithm and calibrate the parameters to the observed correlations in nine management accounting studies. The studies test for an interdependency between management control practices and cite \citet{grabner_management_2013}. The simulation algorithm is based on the objective function \eqref{eq:objective} from the theory. For completeness, we reproduce it here:
\begin{equation*}
y  = \beta_0 + (\beta_{11} + \gamma_1 z + \epsilon_1) x_1 
						+ (\beta_{22} + \gamma_2 z  + \epsilon_2) x_2 
                        + \beta_{12} x_1 x_2 - \frac{1}{2}\delta_1 x^2_1 - \frac{1}{2}\delta_2 x^2_2 + \nu
\end{equation*}
The structural parameters, $\beta$, $\gamma$, and $\delta$ are the same for each simulated firm in a sample, which allows for a clean analysis of our questions. For the main analysis, we set $\beta_0, \beta_{11}, \beta_{22}$ equal to $0$ because these parameters do not interact with the effect of the interdependency. Keeping $\beta_{11}, \beta_{22} = 0$ also ensures that the average optimal level of the practices is in the middle of the random distribution that generates the values of the practices and minimises any ceiling or floor biases in the algorithm. The contingency effects are initially set at $\gamma_1 = 0.33$ and $\gamma_2 = 0$. In an additional analysis, we will compare samples where the contingency effect on the second practise varies from being absent ($\gamma_2 = 0$) to being positive ($\gamma_2 = 0.33$) or negative ($\gamma_2 = -0.33$).  

For each firm, the values for $z$, $\epsilon_1$, and $\epsilon_2$ are simulated as fixed exogenous factors from a normal distribution with mean $0$ and standard deviation $1$,  $\sigma_{\epsilon_1}$, and $\sigma_{\epsilon_2}$ respectively. The $\delta$'s and $\sigma$'s determine the scale and unobserved heterogeneity of the effects, respectively, and interact with the interdependency. In the main analysis, we set these parameters equal to 1 and vary them in follow-up simulations to investigate the robustness of the main analysis. Finally, $\nu$ is normally distributed with standard deviation, $\sigma_{\nu}$. The baseline objective function in the simulation is thus:
\begin{equation}\label{eq:baseline}
\mathbf{y}  = (0.33 \mathbf{z} + \mathbf{\epsilon_1}) \mathbf{x_1} 
						+ \mathbf{\epsilon_2} \mathbf{x_2} 
                        + \beta_{12} \mathbf{x_1} \mathbf{x_2} 
                        - \frac{1}{2}\mathbf{x^2_1} - \frac{1}{2}\mathbf{x^2_2} + \nu
\end{equation}
Note that in this baseline objective function, there is no omitted variable bias in the four specifications with respect to environmental factors. In the next section, we show how the baseline scenario is a good reflection of a typical study in the management accounting survey literature. To investigate whether the different specifications have the power to detect a true effect while maintaining nominal Type I error rates, we will compare samples with a complementarity effect ($\beta_{12} = .25$) to samples without a complementarity effect ($\beta_{12} = 0$).

To examine how the level of optimality affects Type I errors and power, we vary the level of optimality in a sample of firms. The simulation algorithm mimics the process where firms experiment with different configurations of delegation, $x_1$,  and accounting incentives, $x_2$, and keep the configuration that results in the highest business unit profit $y$. The algorithm generates values for $x^o_{1}$, $x^o_{2}$ from two independent uniform distribution between $-5$ and $5$. The range allows the randomly generated values for the practices to be far from the optimal level. Next, the algorithm calculates the performance, $y^o$, according to the above baseline objective function \eqref{eq:baseline}. We repeat this process $O$ times for $x^o_{1}$, $x^o_{2}$ and keep the values for which $y^o$ is the highest in the sample. As a result, the more tries a firm has with different accounting systems, i.e., the greater $O$, the more likely they will adopt the optimal combination of the two practices. The parameter $O$ is thus the key parameter capturing how close the firms in the sample are to the optimal level of the practices. The procedure is described in mathematical form in algorithm \eqref{eq:firm-simulation}. 

\begin{equation}\label{eq:firm-simulation}
\begin{aligned}
	&z \sim \mathcal{N}(0, 1); \epsilon_i ~ \sim \mathcal{N}(0, \sigma_{\epsilon_i}) \\
    \forall 0 < o \leq O: &x^o_i \sim U[-5,5] \\
    \forall 0 < o \leq O: &\hat{y^o} = \beta_0 + (\beta_{11} + \gamma_1 z + \epsilon_1) x^o_1 
						+ (\beta_{22} + \gamma_2 z  + \epsilon_2) x^o_2 
                        + \beta_{12} x^o_1 x^o_2 - \frac{1}{2}\delta_1 {x^o}^2_1 - \frac{1}{2}\delta_2 {x^o}^2_2 \\
     \forall 0 < o \leq O: &y^o \sim \mathcal{N}(\hat{y^o}, \sigma_{\nu}) \\
	 &y^{max} = max(y^1, y^2, ..., y^O)  \\
     &\text{if } y^o = y^{max} \text{then } y = y^o, x_i = x^o_i
\end{aligned}
\end{equation}

\subsection{Calibration to Empirical Studies}\label{optimality}

In order to calibrate the simulation, we collect the correlations of published survey studies that cited \citet{grabner_management_2013} and have an interdependency hypothesis. The median number of observations in the studies is 250 and the average is 265. To give the methods the benefit of the doubt, the simulation will create samples of 300 firm observations where each observations follows the algorithm above. Next, we collect the correlation matrix from 9 studies that report full correlation matrices with correlations between practices, and between practices and environmental factors \citep{dekker_collaborative_2016, grabner_incentive_2014, grabner_cost_2016, bedford_configurations_2015, heinicke_examination_2016, bedford_performance_2019, abernethy_are_2015, sponem_exploring_2016, samagaio_management_2018}. To get an estimate of observed correlations in empirical studies, we calculate the median and 90th percentile absolute correlation between practices and between a practice and a contingency factor. We consider the median value of those statistics to be typical for studies on interdependencies in management accounting. The median absolute correlation between two practices is $0.22$ and the median 90th percentile is $0.39$. The median absolute correlation between a practice and an environmental factor is $0.16$ and the median 90th percentile is $0.30$.

To illustrate the effect of the optimality parameter and the strength of the associations generated by the simulation algorithm, we generate 100 samples with each 300 observations under the baseline scenario outlined above for 6 levels of optimality: $O \in  (2, 4, 8, 16, 32, 64)$. For each sample, we calculate three statistics to illustrate that the simulated samples reflect a typical management accounting study. We plot the statistics for each simulated sample in Figure \ref{calibration}. The first statistic is the correlation between $\mathbf{x_1}$ and $\mathbf{x_2}$ (Panel A) and the second is the correlation between $\mathbf{x_1}$ and $\mathbf{z}$ (Panel B). The absolute correlation between $\mathbf{x_1}$ and $\mathbf{x_2}$ varies between 0 and .5 and is smaller than the median 90th percentile ($.39$) in a typical study except at the higher levels of optimality. Similarly the correlation between $\mathbf{x_1}$ and $\mathbf{z}$ varies between 0 and .4 and is smaller than the median 90th percentile (.30) in a typical study except at the higher levels of optimality. Hence, we conclude that the associations in our simulations are representative for the management accounting literature. 

The third statistic is the non-optimality ratio and quantifies the extent to which deviations from the optimal level $\mathbf{x^*_1|z}$ cannot be explained by the optimality conditions \eqref{eq:optimal}.\footnote{The total deviations from the optimal level given the contingency factor is calculated as the sum of $(x_1 - E(x_1^*|z))^2$ for each observation in the sample, where $E(x_1^*|z)$ is given by the optimality condition \eqref{eq:optimal}. The amount of variation explained by the unobserved factors, $\epsilon_1$ and $\epsilon_2$, can also be calculated from the optimality conditions \eqref{eq:optimal}, i.e., $Var(x_1^*|z) = \frac{\delta_2^2 \sigma_{\epsilon_1}^2 + \beta_{12}^2 \sigma_{\epsilon_1}^2}{(\delta_1 \delta_2 - \beta_{12}^2)^2}$
The non-optimality ratio is then calculated as the ratio between the deviations from optimality not explained by the unobserved factors and the total deviations from optimality.} The non-optimality ratio measures how much of the variation in the practices is caused by the algorithmic search process and how far the practices in a sample are from the optimal levels. The resulting ratio is comparable to an $R^2$ statistic because the non-optimality ratio equals $1$ when the difference between $x_1$ and $x^*_1$ can be fully explained by the absence of optimality in a sample and the ratio equals $0$ when $x_1 = x^*_1$. Figure \ref{calibration} Panel C shows the ratio for the 100 samples for different levels of the optimality parameter $O$. The ratio declines for higher values of the optimality parameter and for all values of $O$ at least $20\%$ of the variation cannot be explained by the optimality condition. In other words, the generated samples always have substantial deviations from optimal practices, which should give performance specifications a chance of detecting performance differences between optimal and sub-optimal accounting systems. 

\begin{figure}
\centerfloat
\includegraphics[width=450px]{figure-latex/sample_descriptives.pdf}
\caption[Calibration of Simulated Samples]{\label{calibration} The figure shows the value of the correlation between $\mathbf{x_1}$ and $\mathbf{x_2}$ (Panel A), the correlation between $\mathbf{x_1}$ and $\mathbf{z}$ (Panel B), and the non-optimality ratio (Panel C),  for 100 samples for 6 different levels (2, 4, 8, 16, 32, 64) of the optimality parameter, $O$. The complementarity effect is either present ($\beta_{12} = 0.25$) or absent ($\beta_{12} = 0$). The decreasing marginal costs are set as $\delta_1 = \delta_2 = 1$. The effect of the environmental variable only affects one of the choices
($\gamma_1 = .33, \gamma_2 = 0$). Lastly, the unobserved variation parameters are set at $\sigma_{\epsilon_1} = \sigma_{\epsilon_2} = \sigma_{\nu} = 1.$}
\end{figure}

\subsection{Power and Type I Error}
In the next section, we will compare the power and type I error rate of the four specifications when varying the optimality parameter, $O$. Because the accounting literature is concerned with testing the hypothesis that there is a (no) complementarity between two management control practices, a focus on power and error rates is appropriate. For completeness, we repeat the four specifications here
\begin{align*} 
\mathbf{x_1} &= \beta_0^d + \beta_{12}^d \mathbf{x_2} 
        + \gamma_{1}^d \mathbf{z}
        + \mathbf{\epsilon^d} \\
\mathbf{y} &=  \beta^{p1}_0 + (\beta^{p1}_{11} + \gamma_1^{p1} \mathbf{z} )\mathbf{x_1} 
						+ (\beta_{22}^{p1} + \gamma_2 \mathbf{z} ) \mathbf{x_2} 
                        + \beta_{12}^{p1} \mathbf{x_1} \mathbf{x_2} 
                        + \delta_1^{p1} \mathbf{x^2_1} + \delta_2^{p1} \mathbf{x^2_2} 
                        + \alpha^{p1} \mathbf{z}
                        + \nu^{p1} \\
 \mathbf{y} &=  \beta^{p2}_0 + (\beta^{p2}_{11} + \gamma_1^{p2} \mathbf{z} )\mathbf{x_1} 
						+ (\beta_{22}^{p2} + \gamma_2 \mathbf{z} ) \mathbf{x_2} 
                        + \beta_{12}^{p2} \mathbf{x_1} \mathbf{x_2} 
                        + \alpha^{p2} \mathbf{z}
                        + \nu^{p2} \\
 \mathbf{y} &=  \beta^{p3}_0 + \beta^{p3}_{11} \mathbf{x_1} 
						+ \beta_{22}^{p3} \mathbf{x_2} 
                        + \beta_{12}^{p3} \mathbf{x_1} \mathbf{x_2} 
                        + \alpha^{p3} \mathbf{z}
                        + \nu^{p3}
\end{align*}
The $\beta_{12}$ coefficients for each specification provide the test for the presence of an interdependency. The simulation generates 1000 samples for each combination of parameters. For each combination, we report the distribution of the t-statistic for the interdependency coefficient and compare it to the traditional cut-off value for the $5\%$ level of significance ($|t| > 1.97$). We calculate the power and type I error rate of the specifications based on the p-value of the test to investigate the performance of the four specifications in more detail. The power is the percentage of samples with a complementarity effect where the p-value is lower than $0.05$ and the estimated coefficient is positive.\footnote{An important caveat is that the power of a study will also be influenced by the size of the effect, measurement error, random variation, and the number of observations in the study. In the simulations, we assumed a fixed effect ($\beta_{12} = 0.25$), no measurement error, fixed the parameters that control random variation, $\sigma_{\epsilon_1}$, $\sigma_{\epsilon_2}$, and $\sigma_{\nu}$, and the number of observations per sample. As a result, the absolute percentages in the results should be interpreted with caution. This study is mainly interested in the relative differences between specifications, focusing on a clean setting and a fair comparison.} The type I error is the percentage of samples without complementarity effect where the p-value is lower than $0.05$ (irrespective of the sign of the estimated coefficient). 

\section{Results}
\subsection{Performance and Demand Specification}\label{performance-and-demand-function-approach}

In the main results section, we compare the power and type I error rate of the four specifications when varying the optimality parameter, $O$, under variations to the baseline scenario. We discuss power and type I error rates sequentially, starting with power.

\subsubsection{Power}\label{Power}
Figure \ref{main} Panel A shows a boxplot for the distribution of t-statistics for each type of test and each combination of parameters. The dot of the boxplot shows the median t-statistic of the 1000 samples, the gap between the whiskers shows the interquartile range, and the whiskers show the minimum and maximum t-statistic. Each boxplot can be compared to the zero line and the dotted lines representing a $95\%$ confidence interval around a null effect. When $\beta_{12} = 0.25$, we expect the distribution of the t-statistic to be above the dotted lines because it shows that the test reliably reports a significant positive interdependency (power).  

Figure \ref{main} Panel A reveals the basic trade-off between the demand specification and the performance specification: with low levels of optimality the performance function is more likely to detect a true complementarity effect while the demand function is more likely to detect a true complementarity effect with high levels of optimality \citep{grabner_management_2013, aral_three-way_2012, johansson_testing_2018}. Interestingly, even at relatively low levels of optimality, $O = 4$, the \emph{demand} specification has similar power to the \emph{performance 1} specification. Figure \ref{calibration} shows that with $O=4$ the optimality condition can at best explain $40\%$ of the variation in the distance between the observed level of the practices and the optimal level of the practices. This implies that, as long as firms avoid the worst possible combinations of management accounting practices, the demand specification is more likely to detect a true effect.

The \emph{performance 2} specification without the quadratic terms fares worse than the \emph{performance 1} specification at lower optimality levels. The omission of the quadratic terms decreases the ability of the \emph{performance 2} specification to detect a real interdependency ($\beta_{12} = 0.25$) at lower levels of optimality. Interestingly, because the omitted variable bias inflates the complementarity with a factor proportional to the correlation between $x_1$ and $x_2$, the \emph{performance 2} specification has more power to detect a real interdependency at higher levels of optimality. In effect, the bias in \emph{performance 2} picks up the same signal as the demand specification. The \emph{performance 3}  specification performs as poorly as the \emph{performance 2}  specification, in terms of power. 

\begin{figure}
\centerfloat
\includegraphics[width=450px]{figure-latex/main_new_plot.pdf}
\caption[Error Rate  and Power of Demand and Performance Specification]
{\label{main} t-static of the performance and demand specification to test
for complementarities when there is a complementarity effect ($\beta_{12} = .25$)
in Panel A or a null ($\beta_{12} = 0$) in Panel B. The boxplots represent the median (the dot) the interquartile range (the gap), and the minimum and maximum (the whiskers). $O$ is varied between 2, 4, 8, 16, 32, and 64. The effect of the environmental variable, $\mathbf{z}$, on the second choice is either absent ($\gamma_1 = .33,   \gamma_2 = 0$), or negative ($\gamma_1 = .33$ and $\gamma_2 = -.33$).}
\end{figure}

\input{tex/main_table.tex}

To evaluate the demand and performance specifications in more detail, we report the power of the four specifications in Table \ref{main-table}. The results show that the "optimality trade-off" between the demand specification and the performance specification that is discussed in the literature \citep{grabner_management_2013, aral_three-way_2012, johansson_testing_2018} is really a second order problem. Both the \emph{demand} and the \emph{performance 1} specification are able to detect a true interdependency with more than $80\%$ probability for low to medium levels of optimality. However, the \emph{demand} specification is more likely to detect a true effect at higher levels of optimality. Strictly speaking, the \emph{demand} specification is more likely to detect a true effect at all levels of optimality but the lowest level, i.e., at \(O = 2\). From a power perspective, the \emph{demand} specification dominates the \emph{performance 1} specification. Finally, the \emph{performance 2} and \emph{performance 3} specifications are not able to detect the true interdependency for most of the parameter space under investigation, except at high levels of optimality. As stated before, the power that these specifications have at higher levels of optimality is due to the bias moving in the same direction as the correlation between \(\mathbf{x_1}\) and \(\mathbf{x_2}\) . While this bias helps with increasing power, it comes at the cost of high type I error rates, as we show now.

\subsubsection{Type I error}\label{Type I error}
Figure \ref{main} Panel B shows a boxplot for the distribution of t-statistics for each type of test and each combination of parameters. When $\beta_{12} = 0$, we expect the distribution of the t-statistic to be centred on $0$, as well as $95\%$ of the distribution to be between the two dotted lines. When the distribution is not centred on $0$, the test is biased. When the distribution is too wide, the test reports too many significant interdependencies in the absence of a true effect (type I error).

Figure \ref{main} Panel B shows that the demand specification, the theoretically appropriate \emph{performance 1} and the \emph{performance 2} specifications have an average t-static close to 0 in the absence of an interdependency. Recall that the omission of the quadratic terms does not bias the estimate of a complementarity in the absence of the complementarity ($\beta_{12} = 0$).

The \emph{performance 3}  specification fares worse than all other specifications. The omission of the interaction terms \(\mathbf{x_1z}\) and \(\mathbf{x_2z}\) biases the estimate of the interdependency when $\gamma_1 \gamma_2 \neq 0$. The bias can be easily seen in Figure \ref{main} Panel B. The distribution of t-statistics for samples without a complementarity effect no longer centre on $0$ when the environmental factor has a contingency effect on the performance of both practices and the bias increases with higher levels of optimality. The bias is negative when $\gamma_2$ is negative and positive for when $\gamma_2$ is positive. The latter case is not depicted in Figure \ref{main}.

To evaluate the Type I errors of the demand and performance specifications in more detail, we report the percentage of samples for which the estimate of $\beta_{12}$ is significantly positive or negative  in Table \ref{main-table}. Under the parameters in the simulation study, the \emph{demand} specification has type I error rates slightly below or equal to $0.05$. This means that the number of false positives are consistent with the nominal p-value of $5\%$. The theoretically appropriate \emph{performance 1} specification tends to have more elevated error rates, two to three times higher than the \emph{demand} specification. The most worrying results are for the \emph{performance 2} and \emph{3} specification. Dropping the quadratic effects increases the error rates in the \emph{performance 2} specification to around $.20$, four times the nominal error rate. The most commonly used specification in the literature, \emph{performance 3}, has even higher type I error rates that increase with higher levels of optimality and when the environmental factor has a contingency effect on both practices. The latter omitted variables, due to a misspecification, lead to a bias in the estimated coefficient for the interdependency and thus the t-statistic. In conclusion, with the parameters in the simulation study only the \emph{demand} specification rejects the null hypothesis at nominal $5\%$ level of significance. The theoretically derived \emph{performance 1} specification has elevated error rates, and the two other performance specifications are even more vulnerable to false positives.

\subsubsection{Take-away of baseline simulation}\label{Take-away of baseline simulation}
The results of the simulation using the baseline model reveal the following. In contrast to arguments put forward in the literature, the \emph{demand} specification has significant power at all levels of optimality. This makes the assumption that a researcher has to make about optimality a second-order issue. In addition, the type I error rates of the \emph{demand} specification are consistent with the nominal p-value of $5\%$. The theoretically appropriate \emph{performance 1} specification has significant power at low to medium levels of optimality, which is in line with arguments in the literature. However, the problem with this specification is the elevated type I errors. These type I errors only get worse once the performance specification is misspecified, as in \emph{performance 2} and \emph{performance 3}.

One way to interpret the elevated type I errors of the performance specifications is to think about how a reader should react when observing a study with a significant positive interaction \(\mathbf{x_1 x_2}\). To demonstrate the problems with the \emph{performance 3} specification, we provide one dramatic example for \(O = 4\) and \(\gamma_2 = -0.33\). If we assume that a priori, we are indifferent between a null effect and a true interdependency of \(\beta_{12} = 0.25\), and we observe one study that reports a significant positive interaction \(\mathbf{x_{1} x_{2}}\), the study is more likely to be from a sample where the null holds than from a sample where there is a true interdependency!

In sum, the results regarding power and type I errors indicate that the \emph{demand} specification performs better on both dimensions compared to all three performance specifications.

\subsection{Parameter Variations}\label{parameter-variations}

In this section, we explore the robustness of the above conclusions to variations in the parameters of the objective functions. Given the large number of possible variations, we first restrict ourselves to theoretically driven comparisons.

\subsubsection{Performance Variation}\label{performance-variation}

We first investigate whether increases in the variance of performance, $\sigma_{\nu}$, change the conclusions. In expectation, this increase in variance has two effects. The first effect decreases the importance of the management practices for performance, which decreases the power of the performance specification. The second effect follows from the first. When the management practices are less important, the level of optimality effects are less pronounced, and the correlations between $\mathbf{x_1}$, $\mathbf{x_2}$, and $\mathbf{z}$ are weaker, which in turn decreases the power of the demand specification and the omitted correlated variable bias in the \emph{performance 2} and \emph{performance 3} specification.

To investigate the role of $\sigma_{\nu}$, we vary the parameter between 1, 2, and 4 while keeping the other parameters the same as in Figure \ref{main}. For clarity of exposition, we limit the number of optimality variations ($O = 2, 8, 32$) and the number of variations of the contingency effect $\mathbf{x_2 z}$ ($\gamma_2 = -.33$).

\begin{figure}
\centerfloat
\includegraphics[width=450px]{figure-latex/noise_new_plot.pdf}
\caption[Error Rate and Power with Increasing Levels of Variability in Performance]
{\label{noise} t-static of the performance and demand specification to test
for complementarities when there is a complementarity effect ($\beta_{12} = .25$)
in Panel A or a null ($\beta_{12} = 0$) in Panel B. The boxplots represent the median (the dot) the interquartile range (the gap), and the minimum and maximum (the whiskers). $O$ is varied between 2, 8, 32. The effect of the environmental variable, $\mathbf{z}$, on the second choice is negative ($\gamma_1 = .0.33$ and $\gamma_2 = -.33$).}
\end{figure}

\input{tex/noise_table.tex}

The results in Figure \ref{noise} and Table \ref{noise-table} are qualitatively the same as the results in Figure \ref{main} and Table \ref{main-table}. Surprisingly, in the presence of an interdependency, the increase in performance variance hardly affects the power of the \emph{demand} specification. At all but the lowest level of optimality, the \emph{demand} specification correctly identifies the interdependency for every simulated sample with a real interdependency, although the t-statistics decrease with higher performance variance. The drop-off in the t-statistic is steeper for the \emph{performance 1} specification to the extent that power drops to around \(20\%\) when \(O = 32\) and \(\sigma_{\nu} = 4\). In summary, these results indicate that the major impact of increasing the performance variance is to decrease the power of the performance specifications and only to a lesser extent decrease the effect of the level of optimality, $O$ on the power of the demand specification.

Regarding type I errors, we find that the \emph{demand}, the \emph{performance 1}, and the \emph{performance 2} specification are unbiased. In addition, the \emph{demand} specification has false positive rates below or close to the nominal rates, while the \emph{performance 1} specification still has elevated type I error rates. The \emph{performance 2} and \emph{performance 3} specification exhibit the same problem as before, elevated false positive rates as a result of misspecification. The increase in unobserved performance variation does lessen the impact of this bias. 

\subsubsection{Marginal Costs}\label{marginal-cost}
 
In this section, we vary the size of the increase in marginal costs, $\delta_1 = \delta_2$. We keep the parameters equal for both management control practices but they become smaller in size. There are two consequences of lowering the increase in marginal costs. First, decreasing $\delta_1 = \delta_2$ increases the importance of the complementarity between the management control practices. Second, the bias from omitting the quadratic terms is smaller. In the baseline scenario, we used $\delta_1 = \delta_2 = 1$. In this section, we compare the baseline scenario to two other values, i.e., $0.25$ and $0$. $\delta_1 = \delta = .25$ is the largest value for which the parameters violate the second-order optimality condition $\beta_{12} < \sqrt{\delta_1 \delta_2}$. The extreme case is when $\delta_1 = \delta_2 = 0$ which may impede the inference by the \emph{demand} specification even further. When the second-order optimality condition is violated, the optimal level for the practices will cluster towards 5 and -5 and away from  0. 

Figure \ref{delta} and Table \ref{delta-table} report the power and type I error rate of the different specifications for samples of firms with slowly increasing ($\delta_i = .25$) or fixed marginal costs ($\delta_i = 0$). Because the results showed no trends for different values of $\gamma_2$, we aggregated the results over all values of $\gamma_2$ in the table. The power of the \emph{demand} specification is generally better for all but the lowest level of optimality and the \emph{performance 1} specification suffers from steep decreases in power with higher levels of optimality. The \emph{demand} specification does suffer from slightly elevated false positives when the marginal costs of the choices are constant or only increasing slowly. However, overall the conclusions are unaffected.

\begin{figure}
\centerfloat
\includegraphics[width=450px]{figure-latex/delta_new_plot.pdf}
\caption[The Error Rate and Power with Different Levels of Marginal Costs]
{\label{delta} t-static of the performance and demand specification to test
for complementarities when there is a complementarity effect ($\beta_{12} = .5$)
in Panel A or a null ($\beta_{12} = 0$) in Panel B. The boxplots represent the median (the dot) the interquartile range (the gap), and the minimum and maximum (the whiskers). $N$ is varied between 2, 8, 32. The effect of the environmental variable, $\mathbf{z}$, on the second choice is negative ($\gamma_1 = .33$ and $\gamma_2 = -.33$). The change in marginal costs varied between $\delta_1 = \delta_2 = 0, .25, 1$}
\end{figure}

\input{tex/delta_table.tex}

\subsubsection{Binary Practices}

An alternative approach to measure accounting practices with fixed or decreasing marginal costs is to treat them as binary decisions because the optimal decision will either be to use the practice to its full extent or not use it at all. When the accounting practices are binary, the quadratic terms in the \emph{performance 1} specification are no longer identified. Hence, we will compare the \emph{demand} with the \emph{performance 2} specification. In the \emph{demand} specification, we have to take into account that the dependent variable is now a binary outcome. Hence, we compare the linear probability model we have used so far, to the logit and probit estimates of the same specification. However, in expectation, these alternative estimation methods should produce the same results in our setting. 

We simulate new samples for the parameters in the main analysis and with the following levels of optimality: 2, 4, 8, 16. The most important change in algorithm \eqref{eq:firm-simulation} is that we generate the accounting choices, $x_i^o$, no longer from a uniform distribution but let them be $-1$ and $1$ with equal probability and we set the parameters $\delta_1$ and $\delta_2$ equal to $0$.

The results are shown in Table \ref{discrete-table}. Because the results showed no trends for different values of $\gamma_2$, we aggregated the results over all values of $\gamma_2$. The power of the tests is lower for all tests compared to the same parameters in Table \ref{main-table} for continuous accounting practices. As before, we find that at all but the lowest level of optimality, the \emph{demand} specification has more power to detect a true effect, independent of the functional form used to estimate the complementarity. All specifications have similar and acceptable Type I error rates. In this specific case, the \emph{performance 2} specification does not suffer from elevated Type I error rates.  With binary practices, we reach the same conclusion as before that the demand specification is superior to the performance specification as long as firms avoid dysfunctional accounting systems. 

\input{tex/discrete_table.tex}

\subsection{Correlated Omitted Variable}

In this section, we investigate to what extent an omitted correlated environmental variable affects our conclusions for the \emph{demand} and \emph{performance 1} specification. The baseline simulation showed that the omission of a contingency factor that affects the performance of both practices, as in \emph{performance 3}, leads to type I errors. However, that correlated omitted variable problem was due to a misspecification, not due to not having access to the data about the variable. To test the vulnerability of the \emph{demand} specification and the \emph{performance 1} specification to spurious correlations in a well designed study, we run the following simulation. We introduce a new unobserved (to the researcher) environmental factor \(\mathbf{w}\) that impacts the performance effect of \(\mathbf{x_1}\) with \(\theta_1\) and the performance effect of \(\mathbf{x_2}\) with \(\theta_2\). 

\begin{figure}
\centerfloat
\includegraphics[width=450px]{figure-latex/spurious_new_plot.pdf}
\caption[Error Rate and Power with Unobserved Environmental Variables]
{\label{spurious} t-static of the performance and demand specification to test
for complementarities when there is complementarity effect ($\beta_{12} = .25$),
in Panel A or a null effect ($\beta_{12} = 0$) in Panel B. The boxplots represent the median (the dot) the interquartile range (the gap), and the minimum and maximum (the whiskers). $O$ is varied between 2, 8, 32. The effect of the unobserved environmental variable, $\mathbf{w}$, on the choices varies from a strong correlation ($\theta_1 = .3$, $\theta_2 = -.3$), a medium correlation ($\theta_1 = .3$ and $\theta_2 = -.2$), and a weak correlation ($\theta_1 =.3$, $\theta_2 = -.1$).}
\end{figure}

\input{tex/spurious_table.tex}

We set the parameters assuming a well designed study that controls for most but not all of the environmental factors affecting the performance of both choices. Based on the nine studies of the calibration section, we set values for the contingency effect of the unobserved factor that reflect a large ($\theta_1 = 0.3, \theta_2 = -0.3$), medium ($\theta_1 = 0.3, \theta_2 = -0.2$), and small ($\theta_1 = 0.3, \theta_2 = -0.1$) spurious correlation. The methodology literature has long argued that an omitted environmental factor will bias the demand specification. The negative bias increases the probability of reporting a substitution effect in the absence of a true effect and decreases the power to reject the null hypothesis when there is a true complementarity.\footnote{A positive bias, i.e., $\theta_1 \theta_2 > 0$, increases the probability of reporting a complementarity effect in the absence of a true effect. The type I errors that might occur because of this correlated omitted variable problem are, by construction, identical to those for $\theta_1 \theta_2 < 0$. Using $\theta_1 \theta_2 < 0$ in our simulation allows us to capture two problems at once, i.e., potentially elevated type I errors and reduced power.}  We theoretically argued above that under the same condition, i.e., $\theta_1 \theta_2 \neq 0$, the performance specification will be biased as well. The results of this simulation reveals to what extent both specifications are vulnerable to this bias.

The results are reported in Figure \ref{spurious} and Table \ref{spurious-table}. These results are consistent with our previous findings. The \emph{demand} specification has at all but the lowest levels of optimality more power to detect a true interdependency than the \emph{performance 1} specification. One logical finding is that the \emph{demand} specification becomes vulnerable to the omitted variable bias and thus higher type I error rates at higher levels of optimality. This effect is most pronounced with the largest spurious correlation (\(\theta_1 = .3\), \(\theta_2 = -.3\)) and \(O = 32\), where we find that in $12\%$ of the simulations with a null effect the \emph{demand} specification reports a significant effect. This finding reinforces that the \emph{demand} specification will only have appropriate type I error rates as part of a well designed study that controls for environmental factors that affect both choices, especially when firms adopt the optimal management controls. However, consistent with our arguments, the \emph{performance 1} specification exhibits the exact same bias and, as a result, the \emph{demand} specification still has superior type I error rates compared to the \emph{performance 1} specification.

\subsection{Robustness and Limitations of the Demand Specification}

In this section we explore under which part of the parameter space the demand specification is less robust than the performance specification. In addition, we investigate whether our conclusion holds for objective functions with three practices and three complementarities and for a combination of discrete and continuous practices. There are two main conclusions to this section. First, the principal weakness of the demand specification is elevated Type I error rates when it is optimal for more than half of the sample to choose the highest level for both practices. This occurs when the practices have no increasing marginal costs (or alternatively, no decreasing marginal returns) and when contingency effects are small. Given how extreme the worst case scenario is, we belief this result only marginally qualifies our main conclusion. In the majority of the management accounting studies we belief that variation in contingency factors and/or decreasing marginal returns will dominate over the direct benefits of the practices. If that is the case, the demand specification has more power to detect a true complementarity at all but the lowest level of optimality while keeping Type I error rates at the nominal $5\%$ level.

Second, the demand specification generally deals well with discrete practices or an objective function with more than two practices and complementarities. Thus, our conclusion and recommendations generalise to this expanded objective function. Nevertheless, in this setting the demand specification suffers from the same inflated Type I error rate when it is optimal for more than half of the sample to choose the highest level for two practices. Because the decision to adopt a discrete practice is inherently all or nothing, the issue is more pronounced for a test of complementarity between two discrete practices. Similarly as before, when the benefits of the practices vary enough in the sample due to contingency effects, the demand specification outperforms the performance specification at all but the lowest level of optimality.

The technical reason for the main weakness of the demand specification is that the corner solution of adopting both practices to their full extent violates the second order optimality condition as discussed in \ref{optimal-level-of-practices}. The three subsections that follow explain the technical details of the simulations and explain how we establish quantitatively that the worst case scenario is unlikely to occur in a typical management accounting setting. The first section investigates an expanded set of parameter combinations to show the robustness of the baseline results in \ref{Take-away of baseline simulation}. Under this simulation, corner solutions are possible for all four combinations and they are all equally likely to occur in the sample.\footnote{The four possible corner solutions are: (1) Fully adopt practice 1 and 2, (2) Fully adopt practice 1 and do not adopt practice 2 at all, (3) fully adopt practice 2 and do no adopt practice 1 at all, and (4) do not adopt practice 1 and 2 at all.} The second section changes the first simulation so that one corner solution (i.e. both practices should be adopted to their full extent) is more likely. The third simulation introduces a third practice in the objective function and allows for discrete practices when one corner solution is more likely. 

\subsubsection{Robustness}

In a first simulation, we vary the following parameters. $\beta_{12}$ equals $0$, $0.25$, or $0.5$. $\delta_1 = \delta_2$ equal $0$, $.25$, $1$, and $1/\delta_1 = \delta_2 = 3$. $\gamma_1 = 0.33$ and $\gamma_2$ equals $0$, $-0.33$, or $0.33$. $\sigma_{\epsilon_1} = \sigma_{\epsilon_2}$ varies between $0.5$, $1$, and $2$ and $\sigma_{\nu}$ equals $1$, $2$, or $4$. Note that these parameter combinations no longer reflect the calibration to a typical management accounting study in section \ref{calibration}. For computational reasons, we restrict ourselves to comparing the two theoretically derived specifications: the \emph{demand} in black and the \emph{performance 1} specification in grey.

\input{tex/big_basis_table.tex}

The results in Table \ref{tab:big-basis-table} largely confirm that only for lower levels of optimality the \emph{performance 1} specification has more power to detect a true effect than the \emph{demand} specification. The major issue for the \emph{performance 1} specification is the inferior Type I error rates as reported in Panel B. The biggest issue for the \emph{demand} specification is the slightly elevated Type I error rate when there are both no increases in the marginal costs of the practices ($\delta_i = 0$) and the unobserved heterogeneity is relatively small ($\sigma_{\epsilon_i} = 0.5$). This is not entirely surprising because these are the conditions where the optimal level for the practices are corner solutions and they violate the second-order optimality condition underlying the demand specification.

\subsubsection{Corner Solutions}

In the next simulation, we exaggerate the effect of the corner solutions by setting the main effects of the two practices, $\beta_{1}$ and $\beta_2$ equal to 0.5. This choice favours one of the four corners, namely where a firm would adopt both practices to their full extent. More specifically under the worst case scenario, i.e., $\sigma_{\epsilon_1} = \sigma_{\epsilon_2} = 0.5$ and $\delta_1 = \delta_2 = 0$, $80\%$ of observations should adopt practice 1 and $80\%$ should adopt practice 2.\footnote{The distribution of the effect of $x_1$ for each firm in the sample is given by a normal distribution with mean $beta_1$ and standard deviation $\sqrt{\sigma_{\epsilon_1}^2 + \gamma_1^2}$. In the worst case scenario for the demand specification this implies a standard deviation of $\sqrt{.25 + 0.11} \approx  0.6$. The probability that the practice is beneficial for a firm is then given by $\Phi(\frac{\beta_1}{0.6}) = \Phi(\frac{0.5}{0.6}) \approx 0.8$ where $\Phi$ is the cumulative standard normal distribution.}
This also implies that $64\%$ of the sample optimally adopts both practices to their full extent even in the absence of a complementarity effect. In other words, for almost two third of the sample the question whether the practices are complements is irrelevant.   

\input{tex/big_main_table.tex}

The results in Table \ref{tab:big-main-table} show that the introduction of the main effects do not affect the power of the demand specification relative to the performance specification. Table \ref{tab:big-main-table} shows that the Type I error rate of the practices breaks down under the worst case scenario and one corner solution outlined above. Increases in unobserved variation in performances ($\sigma_{\epsilon_i}$) and marginal costs ($\delta_i$) largely mitigate the problem. 

\subsubsection{Two Discrete and One Continuous Practice}

Nevertheless, given that corner solutions violate the assumption of the demand specification, we run a last simulation to test the robustness of the demand specification. We extend the objective function to three practices where the first and the third practice are discrete practices. Table \ref{tab:robustness-main-table} reports the power of both specifications to detect a true substitution effect between the first and the second practice ($\beta_{12} = -0.25$) and a true complementarity between the first and the third practice ($\beta_{13} = 0.25$). Table \ref{tab:robustness-main-table} reports the resulting Type I error rates in the absence of these effects. In both panels there is a complementarity between the second and the third practice ($\beta_{23} = 0.25$). $\beta_{12}$ represents a complementarity between a continuous and a discrete practice. $\beta_{13}$ represents a complementarity between two discrete practices.

The remaining parameters are the same as in the previous simulation with two exceptions. First, we need to set the parameters for the direct effect ($\beta_3 = 0.5$) and the contingency effects for the third practice ($\sigma_{\epsilon_3} = \sigma_{\epsilon_1}$, $\gamma_3 = 0.33$). Second, only the continuous, second practice can have increasing marginal costs. 

The results in Table \ref{tab:robustness-main-table} are consistent with Table \ref{tab:big-main-table}. The relative advantage of the demand specification to detect a true effect has not changed. The Type I error rates again show that the demand specification does not adequately control the false positive rate when there is low unobserved heterogeneity ($\sigma_{\epsilon_i} = 0.5$). When almost two third of the sample optimally adopts two practices (to their full extent) in the absence of an interdependency between these practices, the demand specification should not be trusted. Untabulated results show that the problem is less pronounced when there is more unobserved heterogeneity in performance. For the interdependency with only one discrete practice, the problem for the demand specification dissipates when marginal costs of the continuous practice increase ($\delta_1 = 1$). 

The results largely confirm the superiority of the demand specification for a typical management accounting study with one more caveat. When the two practices are discrete and they should be adopted together in the absence of any interdependencies by the majority of the sample ($\sigma_{\epsilon_i} = 0.5$), the demand specification does not adequately control the type I error rate. We argue that this is an uncommon occurrence for most management accounting practices.

\input{tex/robustness_main_table.tex}

\subsection{Contingent Complementarity}

In this section we extend the baseline model by allowing for a contingency effect on the complementarity. That is, we assume that not only the main effect of the practices depends on the environmental factor, $z$, but also the complementarity itself. The simplified objective function for the simulations is then as follows where the parameter $\gamma_{12}$ governs how the complementarity depends on the environmental factor. 

\begin{equation}
\label{eq:contingent-complement}
y = (\gamma_1 z + \epsilon_1) x_1 + (\gamma_2 z + \epsilon_2) x_2 + 
    (\beta_{12} + \gamma_{12} z) x_1 x_2 - \frac{1}{2} x^2_1 - \frac{1}{2} x^2_2 + \nu
\end{equation}

The management accounting literature has shown great interest in investigating whether the strength of complementarity effects varies by environmental factors. For instance \citet{grabner_incentive_2014} reports that subjective performance evaluation and performance based pay are complement for creativity dependent firms but not for other firms. Some researchers test for contingent complementarity effects by splitting the sample into observations with high and low values for the environmental factors and running separate regressions for both samples (using either the performance specification or the demand specification). For instance, they expect a significant complementarity in one sample and no significant complementarity in the other sample. Our results and conclusions so far about the power and type I error respectively directly apply to this approach, where now these issues can also affect the comparison between the subsamples. For example, the approach might miss a true effect in one subsample if the power of the specification is low or alternatively it might erroneously report an effect when the type I error rate of the specification is elevated. 

\input{tex/contingent_complementarity_table.tex}

Others try to estimate the parameter $\gamma_{12}$ more directly. In this approach, the demand specification and performance specification include an additional term to capture the contingent complementarity: respectively $\gamma^d_{12} \mathbf{x_2 z}$ and $\gamma^p_{12} \mathbf{x_1 x_2 z}$. The full \emph{demand}, \emph{performance 1}, and \emph{performance 2} specification are given below. We do not report the \emph{performance 3} specification because it is unlikely that a researcher would exclude $\mathbf{x_1 z}$ or $\mathbf{x_2 z}$ from the regression model when estimating the coefficient of $\mathbf{x_1 x_2 z}$.


\begin{align*} 
\mathbf{x_1} &= \beta_0^d + \beta_{12}^d \mathbf{x_2} + \gamma_{12}^d \mathbf{x_2 z}
        + \gamma_{1}^d \mathbf{z}
        + \mathbf{\epsilon^d} \\
\mathbf{y} &=  \beta^{p1}_0 + (\beta^{p1}_{11} + \gamma_1^{p1} \mathbf{z} )\mathbf{x_1} 
						+ (\beta_{22}^{p1} + \gamma_2 \mathbf{z} ) \mathbf{x_2} 
                        + (\beta_{12}^{p1} + \gamma_{12}^{p1} \mathbf{z}) \mathbf{x_1} \mathbf{x_2} 
                        + \delta_1^{p1} \mathbf{x^2_1} + \delta_2^{p1} \mathbf{x^2_2} 
                        + \alpha^{p1} \mathbf{z}
                        + \nu^{p1} \\
 \mathbf{y} &=  \beta^{p2}_0 + (\beta^{p2}_{11} + \gamma_1^{p2} \mathbf{z} )\mathbf{x_1} 
						+ (\beta_{22}^{p2} + \gamma_2 \mathbf{z} ) \mathbf{x_2} 
                        + (\beta_{12}^{p2} + \gamma_{12}^{p2} \mathbf{z}) \mathbf{x_1} \mathbf{x_2} 
                        + \alpha^{p2} \mathbf{z}
                        + \nu^{p2} \\
\end{align*}

The results in Table \ref{tab:contingent-complementarity-table} report the results of a simulation to evaluate this approach similar to the baseline simulation. In the simulation, we vary the level of optimality $O$ ($2, 4, 8, 16, 32$), the average complementarity, independent of the environmental factor, $\beta_{12}$ ($0$ or $0.25$), the direct contingency effects, $\gamma_1$ ($0.33$) and $\gamma_2$ ($-0.33$ or $0.33$), and the contingency effect on the complementarity, $\gamma_{12}$. Table \ref{tab:contingent-complementarity-table} shows the power to detect a contingent complementarity ($\gamma_{12} = 0.33$ or $-0.33$) and the the type I error rate in the absence of a contingent complementarity ($\gamma_{12} = 0$). 

The results show that demand specification also outperforms the performance specifications to test for a contingent complementarity at all but the lowest levels of optimality. As before, the demand specification has similar or more power to detect a true effect while maintaining better control over Type I error rates at all levels of optimality.

\subsection{Alternative Sample Construction}

In order to investigate the sensitivity of the results to the optimisation algorithm (\ref{eq:firm-simulation}), we test whether the results are sensitive to a different method to construct the sample with varying levels of optimality. In the following simulation, we construct each sample of observations as a mix of a subsample with low optimality ($O = 2$) and a subsample with high optimality ($O = 32$). We vary the proportion of the high optimality subsample between $1/5, 2/5, 3/5$ and $4/5$. 

\input{tex/mix_optimality_table.tex}

Table \ref{tab:mix-optimality-table} reports the results of the simulation where the complementarity is either present ($\beta_{12} = 0.25$) in Panel A or absent ($\beta_{12}$ = 0) and $\gamma_1 = 0.33$ while $\gamma_2 = 0.33$ or $\gamma_2 = -33$. All other parameters are the same as in the baseline simulation in Figure \ref{main}. While the results differ somewhat from the baseline simulation, the overall conclusion remains the same. The biggest difference is that as long as at least $30\%$ of the sample is of low level optimality, the \emph{performance 1} specification has higher power than the \emph{demand} specification to detect a true complementarity. Nevertheless, the Type I error rate of all three performance specifications never comes close to the nominal $5\%$ level. Our conclusion remains that the demand specification is preferred not necessarily because of a trade-off in power between demand and performance specifications but because the demand specifications controls type I error rates better.


\section{Going Forward}

In this section, we use the above results to provide guidance for future studies on interdependencies between the management control practices. First, we explain why it will almost always be better to rely on the demand specification in a research setting without a natural experiment and why researchers should report the results of the demand specification next to the result of the performance specification. Second, we explain how researchers can appropriately control for contingency effects in the performance specifications. Third, we show how the bootstrap and corrections to standard error and degrees of freedom calculations can dramatically improve the type I error rates of the performance specification. Fourth, we show how researchers can combine the results of the demand and performance specification if only one of them reports a significant interdependency.

\subsection{Reporting the Demand Specification}

Our recommendation applies to studies that test for complementarity (or substitution) with cross sectional data where it is unlikely that firms have almost randomly chosen the accounting system. We recommend to always report the demand specification as it will have higher power to detect the complementarity while maintaining appropriate error rates. This recommendation does not put any extra burden on the researcher with respect to data collection because the demand specification does not require additional data compared to the correctly specified performance specification. 

A researchers might be interested in using the performance specification because they are interested in outcomes that are not the ultimate objective of the firm. For instance, researchers who are interested in which accounting system cause stress in employees \citep{shields_design_2000} can use the performance specification to investigate this research question. The success of this approach hinges on whether the intermediate outcome (e.g. stress) is related to the final objective (e.g. job performance). If the intermediate outcome and the final objective are strongly correlated, the intermediate outcome will behave as a noisy measure of the final objective. In that case, the additional noise will be subsumed in the residual term and we showed in Figure \ref{noise} that additional noise hampers the performance specification more than the demand specification. In other words, if the intermediate outcome is strongly related to the final outcome, all the problems with the performance specifications will emerge and the demand specification will be superior to detect an interdependency.

\subsection{Controlling for Contingency Factors}

One advantage of the performance specification is that it can directly estimate the size of the complementarity in terms of a performance increase. In order to report this estimate, a researcher should estimate the performance specification with the inclusion of all interactions between the accounting practices, such as delegation and incentives, and contingency factors that affect the performance of the practices, such as environmental uncertainty. 

\citet{bedford_management_2016} provide an example of how to control for environmental dynamism in a complementarity test with the performance specification. For instance, Table 6 reports the test for the complementarity effect of interactive control and firm structure on management control effectiveness and controls for the interaction between environmental dynamism and interactive control and between environmental dynamism and firm structure. The regression formula for the test with management control effectiveness as dependent variable is 

\begin{align*}
MCEFFECT &= \beta_0 + \beta_1 INT + \beta_2 STRUCT + \beta_{12} INT \times STRUCT \\
&+\gamma_0 ENVDYN + \gamma_1 ENVDYN \times INT + \gamma_2 ENVDYN\times STRUCT \\
&+ CONTROLVARS 
\end{align*}

When there are a large number of contingency factors that need to be included, the performance specification has to include a large number of interactions which can yield unstable estimates. We recommend that researchers use a dimension reduction technique such as principal component analysis on the contingency factors to reduce the number of variables and interactions in the regression. This recommendation assumes that researchers are mainly interested in estimating the complementarity and only include the contingency factors as control variables.

\subsection{Correcting Type I Errors}

Further, we address the type I error rates of the performance specification. Even after adjusting for contingency factors, the results show that the performance specification consistently reports a higher proportion than the nominal false positive rate of $5\%$. We propose two solutions to this problem. The first one is the bootstrap approach, which relies on repeated resampling of the data to empirically estimate the true distribution of the interdependency parameter \citep{efron_computer_2017}. The second one relies on adjustments to the estimates of the standard error and degrees of freedoms that are used to calculate the t-statistic and p-value of the interdependency estimate \citep{young_improved_2016}.

The bootstrap requires to run the performance specification repeatedly after resampling the data with replacement. The assumption of the bootstrap is that the data in the sample are representative of the broader population and that resampling from this sample approximates the variation in the population. To show the impact of bootstrapping, we run for each resampled dataset the performance specification, keep the estimate $\beta_{12}^{p3}$ , and use the distribution of these estimates to decide whether the complementarity is statistically significant. If the $95\%$ bias-corrected and accelerated confidence interval does not include $0$, the complementarity is considered significant \citep{efron_computer_2017}. We use the recommended $2000$ repetitions to get accurate estimates of the confidence interval \citep{efron_computer_2017}. 

We test the type I error rate and the power of the bootstrap for the \emph{performance 1} specification on a subset of the parameters of the main analysis. The computational burden of the bootstrap forces us to limit the parameter space. Specifically, we limit the effect of the contingency factor $z$ on $x_2$ to two values ($\gamma_2 = 0.33$ and $\gamma_2 = -0.33$) and we limit the values of the level of optimality to three values ($O=2$, $O=8$, and $O=32$). The results in Table \ref{bootstrap-table} show that the bootstrap reduces the type I error rates of the performance specification considerably, close to the nominal $5\%$.  Unfortunately, the improvement in error rates comes at the cost of reduced power to detect a true complementarity.

\input{tex/bootstrap_table.tex}

\citet{young_improved_2016} proposes a computationally efficient alternative adjustment. The adjustment uses the result that the standard error of a coefficient estimate is expected to be chi-squared distributed when the residuals of the regression are normally distributed. \cite{young_improved_2016} proposes an adjustment to the standard errors to allow deviations from normality and account for the possibility of influential outliers. In addition, he proposes a further adjustment to the degrees of freedom of the chi-squared distribution and thus of the t-statistic of the coefficient, to account for the fact that the data does not contain completely independent observations. Recall that one of the problems for the performance specification is that optimally designed accounting systems are completely determined by the contingency factors and thus firms in the same environment have the same optimal accounting system. In other words, firms in the same environment are not independent from each other. As a result, the adjustments to the standard errors and degrees of freedom are appropriate to improve the performance specification.

We rerun the main analysis for the \emph{demand} and \emph{performance 1} specification. Table \ref{nearly-table} reports the type I error rate and power of both specifications with and without the corrections. For ease of exposition, we have aggregated the simulations over the different values of $\gamma_2$. The results show that the corrections almost bring the type I error rates of the \emph{performance 1} specification to the nominal level of $5\%$. As with the bootstrap results, this comes at the cost of a decrease in the power to detect a true complementarity.\footnote{The corrected standard errors are $2.8\%$ ($O = 2$) to $1\%$ ($O = 64$) smaller for the demand specification and $34\%$ ($O = 2$) to $25\%$ ($O = 64$) higher for the performance specification. The corrected degrees of freedom are $53\%$ ($O = 2$) to $64\%$ ($O = 64$) smaller for the demand specification and $77\%$ ($O = 2$) to $85\%$ ($O = 64$) for the performance specification. The correction of the standard errors have the largest impact on the improvement of the performance specification error rate. In practice, the degree of freedom correction could be as beneficial in smaller samples.}

\input{tex/nearly_table.tex}

Because the power and type I error rate of the bootstrap and the \citet{young_improved_2016} corrections are indistinguishable, researchers can report results on the performance specification adjusting the OLS results with either of those methods. The bootstrap approach has the advantage that it is more flexible and applicable to other functional forms and multiple equation models. Most modern statistical packages have the functionality to run bootstrap tests. The corrections to the standard error and degrees of freedom are generally faster but limited to linear models. STATA users can use the script on Alwyn Young's website, while R users can use the functions in Appendix \ref{appendix-R}.\footnote{\url{http://personal.lse.ac.uk/YoungA/}}

\subsection{Combining Performance and Demand Specification}

Because the power of the performance specification decreases with the level of optimality while the power of the demand specification increases, a researcher might be tempted to run both regressions and decide that a complementarity is real if either of the regressions reports a significant effect. We assess this combined strategy in Table \ref{nearly-table}. The results show that independent of the level of optimality the combined approach with and without the correction leads to inflated type I error rates. Further investigation of the results shows that for a given sample the probability of a false positive in the demand specification is independent of the probability of a false positive in the performance specification.  Therefore, we recommend that researchers use a significance level of $2.5\%$ for each test to keep the Type I error rate at $5\%$ when combining the demand specification and the performance specification. Untabulated results show that this strategy contains the overall Type I error rate to the nominal $5\%$.

\section{Summary and discussion}\label{summary-and-discussion}

This study builds on earlier studies on complementarity theory \citep{milgrom_complementarities_1995, grabner_management_2013}, to provide guidance on how to test for the presence of interdependencies in management control systems. The results of the simulation study show that in most common scenarios the assumptions of optimality should not be the main driver in deciding between the demand or the performance specification. In fact, unless researchers can make the case that a large number of firms have a dysfunctional management control system, the demand specification should be the preferred statistical method. A straight-forward check on the optimality assumption is to investigate the correlation between the practices and the environmental variables. Non-trivial levels of optimality in the sample will induce correlations between management accounting practices and environmental factors when there are contingency effects.\footnote{The absence of any correlations does not imply the absence of high levels of optimality, as multiple contingency effects can cancel each other out. Another clarification about the superiority of the demand specification is that it does not imply that the demand specification provides evidence for high levels of optimality. A statistically significant interdependency effect in the demand specification only implies that firms on average avoid the worst possible management control systems, not that they have on average the optimal control system.}.

When performance data is available, the performance specification can be estimated as an additional test in combination with the demand specification. The performance specification can be expected to yield acceptable estimates when there is considerable variation between firms in the same environment. However, the results of this study show the importance of adequately controlling for contingency factors and adjust the estimates of standard errors. As far as we know, the current accounting literature does not fully address these problems which lead to substantial increases in type I error rates and a loss of power.

The most important weakness of the demand specification is that it assumes that the performance benefits of management control practices are decreasing with more extensive use. If this second-order condition does not hold, the demand specification might have elevated levels of false positives. We suggest that researchers verify the distribution of the management practices to check whether the second-order condition holds. If one of the management practices has more observations at the extremes of the measurement scale than at the centre, the second order condition might be violated and the results of both the demand and the performance specification should be interpreted with some caution. A conservative approach is to treat the practices as binary choices. 

This study has several limitations.  Our preferred approach, the demand specification, does not allow to directly estimate the performance effect of the interdependency. More sophisticated models are needed to reliably estimate this performance effect. The economics literature has proposed and used a multiple equation model that combines both demand and performance functions \citep{athey_empirical_1998, gentzkow_valuing_2007, kretschmer_competitive_2012, miravete_innovation_2006}. Further research can investigate the properties of these statistical models for the management control setting. An additional advantage of the models is that they can incorporate the effect of unobserved contingency factors and unobserved interdependent practices. A more detailed discussion of these issues goes beyond the scope of this study.

Another limitation of the current study is that the level of optimality is implemented with a naive algorithm that lacks external validity. Better theoretical models of how firms choose management accounting practices can improve upon our understanding of the distribution of management accounting practices and their interdependencies. The approach of Hemmer and Labro \citeyearpar{hemmer_management_2019} is one potential avenue to further explore. They model the firm's choices as decisions under incomplete information with Bayesian updating when more information becomes available. In these models, firms can end up with ex-post sub-optimal management control systems because they lack the appropriate information to choose the optimal system. The parameter governing the lack of information can replace our optimality parameter, \(O\). Further innovations in these models can allow researchers to directly estimate the extent to which firms lack information and choose sub-optimal management control practices.

\pagebreak
 
\appendix
\renewcommand{\theequation}{A.\arabic{equation}}
\setcounter{equation}{0}

%\section{General Theory}\label{appendix-general}
%\subsection{General Objective Function}
% 
%Assume that a firm chooses the level of $N$ management accounting practices which depend on $M$ contingency factors. The levels of the management accounting practices are a vector $\mathbf{x}$ and the level of the environmental factors is a vector $\mathbf{z}$. Performance, $y$, depends on a factor $\nu$ while the performance effects of each management control practices further depends on a factor $\mathbf{\epsilon}$. In our model, $\mathbf{x}$ and $\mathbf{z}$ are observed by the researcher but $\mathbf{\epsilon}$ and $\nu$ are not. 
% 
%% z and x are column vectors (M x 1) and (N x 1)
% 
%In matrix notation, we can write
% 
%\begin{equation} \label{eq:structural-matrix}
%y = \beta_0 + (\mathbf{\beta_1}^T + \mathbf{z^T} G^T + \mathbf{\epsilon^T})
%     \mathbf{x} + \frac{1}{2}\mathbf{x^T} B \mathbf{x} + \nu
%\end{equation}
%
%$G$ is a $N \times M$ matrix where each element $\gamma_{nm}$ represents the contingency effect of, $z_m$, on practice $x_i$. $B$ is a symmetric $N \times N$ matrix with $\beta_{ij} = \beta_{ji}$ as off-diagonal elements and a vector $-\mathbf{\delta}$ on the diagonal. The off-diagonal elements represent the interdependency between two practices. This follows directly from the definition of an interdependency as the cross derivative of performance to two practices, $\frac{\partial y}{\partial x_i \partial x_j} = .5 \beta_{ij} + .5 \beta_{ji} = \beta_{ij}$. The elements of $\mathbf{\delta}$ represent the second derivative of the performance effects of the practices. We assume that all $\delta_n$ are positive which implies increasing marginal costs to the practices. The elements of $\mathbf{\epsilon}$ and $\nu$ are independent which implies that the model contains all environmental variables and practices that effect the performance of any two practices $x_i$ and $x_j$. 
% 
%\subsection{Optimal Level and Conditional Correlations}
%
%Next, we derive the optimal level for all practices. The quadratic optimisation problem has a standard solution for the performance function in equation \eqref{eq:structural-matrix} under the condition that $-B$ is positive definite. The second order condition that -B is positive definite implies that for every combination of practices, $\delta_i \delta_j - \beta_{ij}^2 > 0$. The solution can be written as follows.
% 
%\begin{equation} \label{eq:optimal-matrix}
%\begin{aligned} 
%    \mathbf{\beta_1} + G \mathbf{z} + \mathbf{\epsilon} & = -B \mathbf{x^*} \\
%    - B^{-1} (\mathbf{\beta_1} +  G \mathbf{z} + \mathbf{\epsilon})  & = \mathbf{x^*}
%\end{aligned}
%\end{equation}
% 
%In this formulation, the optimal level for each practice has mean $-B^{-1} (\mathbf{\beta_1} + G \mathbf{z})$ and covariance matrix $\Omega = -S_{\epsilon} B^{-1} S_{\epsilon}$ where $S_{\epsilon}$ is the a diagonal matrix with the standard deviations $\sigma_e$ on the diagonal. 
%
%Because $-B$ is positive definite, write $-B^{-1} = DRD$ where $R$ is the correlation matrix of $\Omega$ and $D$ is a diagonal matrix with strictly positive values on the diagonal. The partial correlation between the optimal level of two practices, $x^*_i$ and $x^*_j$ is than given by $-\frac{R^{-1}_{ij}}{\sqrt{R^{-1}_{ii} R^{-1}_{jj}}}$. 
%
%Because $R^{-1} = - D^{-1}BD^{-1}$, the partial correlation between the optimal level of two practices conditional on all other practices and environmental factors equals 
%
%\begin{equation}\label{eq:conditional-practices}
%cor(x_i^*, x_j^* | X_{-i, -j}, Z)  = \rho^*_{ij} = \beta_{ij}\lambda_{ij}^* \text{ with } \lambda_{ij}^* > 0. 
%\end{equation}
%
%Similarly
%
%\begin{equation}\label{eq:conditional-contingency}
%cor(x_i^*, z_k | X_{-i}, Z_{-m})  = \omega^*_{ik} = \gamma_{ik}\zeta_{ik}^* \text{ with } \zeta_{ik}^* > 0. 
%\end{equation}
% 
%We assume that with randomly chosen practices ($O = 0$) the empirical conditional correlations equal $0$. The conditional correlations are between $0$ and the maximum in \eqref{eq:conditional-practices} and \eqref{eq:conditional-contingency} when $O > 0$.
%
%\begin{align*}
%\rho_{ij} &= \lambda_{ij} \beta_{ij}
%& \omega_{ik} &= \zeta_{ik} \gamma{ik} \\
%\rho_{ij}(O = 0) &= \lambda_{ij}(O = 0) = 0 
%& \omega_{ik}(O = 0) &= \zeta_{ik}(O = 0) = 0 \\
%0 & \leq \lambda_{ij} \leq \lambda^*_{ij}
%& 0 & \leq \zeta_{ij} \leq \zeta^*_{ij} \\
%\frac{\delta \lambda_{ij}}{\delta O} & \geq 0 
%& \frac{\delta \zeta_{ij}}{\delta O} & \geq 0 
%\end{align*}
% 
%% \subsection{Binary Practices}
%% 
%% With binary practices, the production function simplifies because $x = x^2$. We can set the parameters of decreasing marginal costs to zero, i.e. $\mathbf{\delta} = 0$. $\beta_{ii}$ now captures the increase in performance from adopting practice $x_i$ when no other practices are adopted and in the absence of any contingency effects. We replace $B$ with $B_0$ which has the same off-diagonal elements as $B$ but $0$ on the diagonal. The optimal decision rule for a firm is to adopt a practice $i$ when profit $y$ is higher for $x_i = 1$ than for $x_i = 0$. 
% 
%% \begin{equation} \label{eq:condition-binary}
%%     \beta_{ii} + \mathbf{z^T} \mathbf{\gamma_i} + \epsilon_i 
%%     + \sum^{N}_{k = 1, k \neq i} \beta_{ik} x_k > 0
%% \end{equation}
%% 
%% Similarly, it is optimal for firms to adopt two practices $i$ and $j$ when the performance is higher than the performance compared to (1) adopting none of the practices, (2) adopting only practice $i$, and (3) adopting only practice $j$. 
%% 
%% \begin{equation} \label{eq:condition-two-binary}
%%     \begin{aligned}
%%         \beta_{ii} + \mathbf{z^T} \mathbf{\gamma_i} + \epsilon_i
%%         + \beta_{jj} + \mathbf{z^T} \mathbf{\gamma_j} + \epsilon_j
%%         + \beta_{ij} + \sum^{N}_{k = 1, k \neq i,j} (\beta_{ik} + \beta_{jk}) x _k &> 0 \\
%%         \beta_{jj} + \mathbf{z^T} \mathbf{\gamma_j} + \epsilon_j 
%%         + \beta_{ij} + \sum^{N}_{k = 1, k \neq i,j} \beta_{jk} x_k &> 0 \\
%%         \beta_{ii} + \mathbf{z^T} \mathbf{\gamma_i} + \epsilon_i
%%         + \beta_{ij} + \sum^{N}_{k = 1, k \neq i,j} \beta_{ik} x_k &> 0 
%%     \end{aligned} 
%% \end{equation}
%% 
%% This line of reasoning can be extended for the necessary inequality conditions for the optimal adoption of $p \leq N$ binary practices. However, we do not need the complete set of conditions to illustrate that the same set of conclusions hold as for the continuous practices. First, whether a practice is optimally adopted depends on the contingency factors. Second, whether two practices are adopted together depends the interdependency parameter $\beta_{ij}$. In the absence of interdependencies, $\beta_{12} = 0$, the second and third condition in equation \eqref{eq:condition-two-binary} simplify to the condition \eqref{eq:condition-binary} and when they are both satisfied, the first condition holds as well. That is, in the absence of an interdependency between practices, the adoption of one practice is not a function of the adoption of the other practice.
%
%% As explained in the previous section, when firms adopt the optimal practices, $x^*_i$, they are a function of the contingency factors, $z_m$, when $\gamma_{im} \neq 0$ and conditional on all other practices and contingency factors. Similarly, the practices $x^*_i$ and $x^*_j$ are a function of each other conditional on all other environmental factors when $\beta_{ij} \neq 0$. In the remainder of this section, we will work with the more tractable continuous model where the partial correlation is a either $\gamma_{im}$ or $\beta_{ij}$ scaled by a positive factor. The derivations for binary practices depend on additional assumptions about the distribution of the unobservable contingency factors $\epsilon$. Nevertheless, the qualitative conclusions are expected to hold for binary practices and we will test these expectations in the simulation study.
%% 
%% The strength of the conditional correlation between practices and environmental factors will also depend on the extent to which firms have adopted optimal practices. We assume that the conditional correlation between practices and environmental factors equals $0$ when firms adopt practices in complete ignorance of the optimal level, while the conditional correlation goes to $\gamma_{im}\zeta_{im}^*$ when all firms adopt the optimal level of each practice. Similarly, we assume that the actual observed conditional correlation between two practices will depend on the extent to which firms have adopted the optimal level for each practice. In complete absence of knowledge about the optimal levels, the conditional correlation is assumed to be $0$ while it goes to $\beta_{ij}\lambda_{ij}^*$ when firms adopt the optimal levels. 
% 
%\subsection{Performance Specification.}
% 
%The performance function approach estimates the performance equation \eqref{eq:structural-matrix} directly. 
%
%\subsubsection{Specifications}
%
%\emph{Performance 1}
% 
%\begin{equation*}
%    y = \beta_0^{p1} + \mathbf{\beta_z^{p1^T} z} + (\mathbf{\beta_1^{p1^T}} + \mathbf{z^T} G^{p1^T}) \mathbf{x} + 
%    \frac{1}{2}\mathbf{x^T} B^{p1} \mathbf{x} + \nu^{p1}
%\end{equation*}
%
%\emph{Performance 2}
%
%\begin{equation*}
%    y = \beta_0^{p2} + \mathbf{\beta_z^{p2^T} z} + (\mathbf{\beta_1^{p2}} + \mathbf{z^T} G^{p2}) \mathbf{x} + 
%    \frac{1}{2}\mathbf{x^T} B_0^{p2} \mathbf{x} + \nu^{p2}
%\end{equation*}
%
%\emph{Performance 3} 
% 
%\begin{equation*}
%    y = \beta_0^{p3} + \mathbf{\beta_z^{p3^T} z} + \mathbf{\beta_1^{p3}} \mathbf{x} + 
%    \frac{1}{2}\mathbf{x^T} B_0^{p3} \mathbf{x} + \nu^{p3}
%\end{equation*}
%
%% \subsubsection{Lack of Power}
% 
%% In the remainder of this section, we explain the potential problems with these three specifications. All three specifications, will suffer form the well known problem we explained above that performance is no longer a function of the management practices when firms adopt the optimal practices \citep{grabner_management_2013}. With strictly optimal practices, there is no longer information about the practices in the performance variable. The literature advises that for a performance specification to have sufficient power, there need to be a sufficient number of firms that are not adopting the optimal level of the practices \citep{bedford_management_2016, carree_note_2011, hofmann_organizational_2017}. However, the literature has not gone beyond this rule of thumb to investigate how strong the deviations from optimality need to be. Our simulation study will provide an answer to this question.
% 
%\subsubsection{Omitted Contingency Effect}
%
%Because of \eqref{eq:conditional-practices}, we can write $\mathbf{z_m} = \gamma_{im} \zeta^p_{im} \mathbf{x_i} + \gamma_{jm} \zeta^p_{jm} \mathbf{x_j} + \mathbf{\epsilon_z}$ with $E(\mathbf{x_i \epsilon_z}) = 0$ and $E(\mathbf{x_j \epsilon_z}) = 0$.
% 
%\begin{align*}
%\gamma_{im} \mathbf{z_m} \mathbf{x_i} + \gamma_{jm} \mathbf{z_m} \mathbf{x_j}
%= \gamma^2_{im} \zeta^p_{im} \mathbf{x_i}^2 + \gamma^2_{jm} \zeta^p_{jm} \mathbf{x_j}^2 
%    + \gamma_{im} \gamma_{jm} (\zeta^p_{im} + \zeta^p_{jm}) \mathbf{x_i x_j} 
%    + \epsilon_z ( \mathbf{x_i} + \mathbf{x_j})\\
%\end{align*}
%
%If $\mathbf{x_i}$, $\mathbf{x_j}$, $\mathbf{z}$ follow a multivariate standard normal distribution, 
%
%\begin{align*}
%    cov(\mathbf{x_i x_j}, \mathbf{x_i^2} | X_{-i, -j}, Z) 
%    &= E(\mathbf{x_i}^3 \mathbf{x_j}) - E(x_i x_j) E(x_i^2) \\
%    &= 2 E(\mathbf{x_i x_j}) E(\mathbf{x_i}^2) \\
%    &= 2 \widetilde{\lambda_{ij}} \beta_{ij}
%\end{align*}
%
%The bias of omitting $\mathbf{z_m x_i}$ and $\mathbf{z_m x_j}$ from the performance specification is then proportional to
%
%\begin{align*}
%    cov(\mathbf{x_1 x_2, \gamma_{im} \mathbf{z_m} \mathbf{x_i} + \gamma_{jm} \mathbf{z_m} \mathbf{x_j}} | X_{-i, -j}, Z_{-m}) = \\
%    (\gamma^2_{im} \zeta^p_{im} + \gamma^2_{jm} \zeta^p_{jm}) \lambda^p_{ij} \beta_{ij} + \gamma_{im} \gamma_{jm} (\zeta^p_{im} + \zeta^p_{jm})  
%\end{align*}
%
%The bias is 0 when $\zeta^p_{im} = \zeta^p_{jm} = 0$ or when $\beta_{ij} = 0$ and either $\gamma_{im} = 0$ or $\gamma_{jm} = 0$.
%
%\subsubsection{Omitted Third Practice}
%
%Because of \eqref{eq:conditional-practices}, we can write $\mathbf{x_k} = \beta_{ik} \lambda^p_{ik} \mathbf{x_i} + \beta_{jk} \lambda^p_{jk} \mathbf{x_j} + \mathbf{\epsilon_x}$ with $E(\epsilon_x x_i) = 0$ and $E(\epsilon_x x_j) = 0$
%
%\begin{align*}
%    \beta_{ik} \mathbf{x_k} \mathbf{x_i} + \beta_{jk} \mathbf{x_k} \mathbf{x_j}
%    = \beta^2_{ik} \lambda^p_{ik} \mathbf{x_i}^2 + \beta^2_{jk} \lambda^p_{jk} \mathbf{x_j}^2 
%    + \beta_{ik} \beta_{jk} (\lambda^p_{ik} + \lambda^p_{jk}) \mathbf{x_i x_j} 
%    + \epsilon_x ( \mathbf{x_i} + \mathbf{x_j})\\
%\end{align*}
%
%The bias of omitting $\mathbf{x_k x_i}$ and $\mathbf{x_k x_j}$ is then proportional to 
%
%\begin{align*}
%   cov(\mathbf{x_i x_j}, \beta_{ik} \mathbf{x_k} \mathbf{x_i} + \beta_{jk} \mathbf{x_k} \mathbf{x_j}| X_{-i, -j, -k}, Z) = \\
%   (\beta^2_{ik} \lambda^p_{ik} + \beta^2_{jk} \lambda^p_{jk}) \lambda_{ij}^p \beta_{ij} + \beta_{ik} \beta_{jk} (\lambda^p_{ik} + \lambda^p_{jk})
%\end{align*}
%
%The bias is 0 when $\lambda^p_{ik} = \lambda^p_{jk} = 0$ or when 
%$\beta_{ij} = 0$ and $\beta_{jk} = 0$ or $\beta_{ik} = 0$.
%
%% A special case of the above problem is the omission of the quadratic terms $\delta_i \mathbf{x_i}^2$ where $\mathbf{x_i} =  \beta_{ij} \lambda^p_{ij} \mathbf{x_j} + \mathbf{\epsilon_x}$. As a result, this omission will bias the estimate of $\beta_{ij}$ with $\beta_{ij} 
%% \delta_i \lambda^p_{ij}$. Since $\lambda^p_{ij} > 0$, this bias will not change the sign of the estimate but will inflate the estimate with a factor $1 + \delta_i \lambda^p_{ij}$.  This result also implies that the omission will not bias estimates when $\beta_{ij} = 0$. The omission of the quadratic term is the difference between the \emph{performance 1} and \emph{performance 2} specification.
%
%\subsection{Demand Specification}
%
%\begin{equation*} 
%    \mathbf{x_i} = \beta_0^d + \beta_{ij}^d \mathbf{x_j} 
%	+ \sum_{k = 1, k \neq i,j}^N \beta_{ik}^d \mathbf{x_k} 
%    + \sum_{m = 1}^M \gamma_{im}^d \mathbf{z_m}
%    + \mathbf{\epsilon^d}
%\end{equation*}
%
%\begin{align}
%\beta_{ij}^d & \propto cor(\mathbf{x_i}, \mathbf{x_j} | X_{-i, -j}, Z) \nonumber \\
%          & \propto \lambda_{ij} \beta_{ij} \label{eq:demand-propto}
%\end{align}
%
%% \subsubsection{Lack of Power}
%
%\subsubsection{Simultaneity Bias}
%
%Because of \eqref{eq:demand-propto} $\beta_{ij}^d$ always has the same sign as $\beta_{ij}$. $\beta_{ij}$ cannot be exactly estimated but inference about it's sign is correct. 
%
%\subsubsection{Omitted Contingency Factor}
%
%Because of \eqref{eq:conditional-contingency}, we can write $\mathbf{z_m} = \gamma_{im} \zeta^d_{im} \mathbf{x_i} + \gamma_{jm} \zeta^d_{jm} \mathbf{x_j} + \mathbf{\epsilon_z}$ with $E(\mathbf{x_i \epsilon_z}) = 0$ and $E(\mathbf{x_j \epsilon_z}) = 0$. When $\mathbf{z_m}$, $\mathbf{x_i}$, and $\mathbf{x_j}$ follow a multivariate normal distribution: $-1 \leq \gamma_{im} \zeta^d_{im}, \gamma_{jm} \zeta^d_{jm} \leq 1$. 
%
%\iffalse
%\begin{align*}
%\mathbf{x_i} &= \beta_{ij} \lambda^d_{ij} \mathbf{x_j} + 
%\gamma_{im} \zeta^d_{im} (\gamma_{im} \zeta^d_{im} \mathbf{x_i} + \gamma_{jm} \zeta^d_{jm} \mathbf{x_j} + \mathbf{\epsilon_z}) + \mathbf{\epsilon_i} \\
% (1 - (\gamma_{im} \zeta^d_{im})^2) \mathbf{x_i} &= \mathbf{x_j} (\beta_{ij} \lambda^d_{ij}
%+ \gamma_{im} \zeta^d_{im} \gamma_{jm} \zeta^d_{jm} )  +  \gamma_{im} \zeta^d_{im}  \mathbf{\epsilon_z} + \epsilon_{i} 
%\end{align*}
%\fi
%
%the bias of omitting $\mathbf{z_m}$ is then proportional to
%
%\begin{align*}
%    cov(\mathbf{x_j}, \gamma_{im} \zeta^d_{im} \mathbf{z_m} | X_{-i, -j}, Z_{-m}) = \frac{\gamma_{im} \gamma_{jm} \zeta^d_{im} \zeta^d_{jm}}{1 - (\gamma_{im} \zeta^d_{im})^2}
%\end{align*}
%
%the bias is 0 when either $\zeta^d_{im} = 0$, $\zeta^d_{jm} = 0$, $\gamma_{im} = 0$, or $\gamma_{jm} = 0$.
%
%\subsubsection{Omitted Third Practice}
%
%Because of \eqref{eq:conditional-practices}, we can write $\mathbf{x_k} = \beta_{ik} \lambda^d_{ik} \mathbf{x_i} + \beta_{jm} \lambda^d_{jk} \mathbf{x_j} + \mathbf{\epsilon_x}$ with $E(\mathbf{x_i \epsilon_x}) = 0$ and $E(\mathbf{x_j \epsilon_x}) = 0$. When $\mathbf{x_k}$, $\mathbf{x_i}$, and $\mathbf{x_j}$ follow a multivariate normal distribution: $-1 \leq \beta_{ik} \lambda^d_{ik}, \beta_{jk} \lambda^d_{jk} \leq 1$. 
%
%The bias of omitting $\mathbf{x_k}$ is then proportional to
%
%\begin{align*}
%    cov(\mathbf{x_j}, \beta_{ik} \lambda^d_{ik} \mathbf{x_k} | X_{-i, -j, -k}, Z) = \frac{\beta_{ik} \beta_{jk} \lambda^d_{ik} \lambda^d_{jk}}{1 - (\beta_{ik} \lambda^d_{ik})^2}
%\end{align*}
%
%The bias is 0 when either $\lambda^d_{ik} = 0$, $\lambda^d_{jk} = 0$, $\beta_{ik} = 0$, or $\beta_{jk} = 0$.
%
\section{Omitted Variable Bias} \label{appendix-omitted}

The bias of omitting the term $\mathbf{x_1 z}$ on the estimate of $\beta^{p3}_{12}$ is given by $\gamma_1 \frac{cov(\widetilde{\mathbf{x_1 x_2}}, \widetilde{\mathbf{x_1 z}})} {var(\widetilde{\mathbf{x_1 z}})}$ where $\widetilde{\mathbf{x_1 x_2}}$ and $\widetilde{\mathbf{x_1 z}}$ are the residual vector of regressing $\mathbf{x1}$, $\mathbf{x2}$, and $\mathbf{z}$ on $\mathbf{x_1 z}$ and $\mathbf{x_1 z}$ respectively \citep{angrist2008mostly,cunningham_causal_2018}. 
Assume that $\mathbf{x1}$, $\mathbf{x2}$, and $\mathbf{z}$ are multivariate standard normal with correlations $r_{12}$, $r_{2z}$, and $r_{1z}$. We can use the \citet{isserlis_formula_1918} formula to derive the covariance between an interaction and one of the variables. 

\begin{align*}
cov(\mathbf{x_1 x_2}, \mathbf{x_1}) &= E(\mathbf{x_1}^2 \mathbf{x_2}) - E(\mathbf{x_1 x_2}) E(\mathbf{x_1}) \\
&= 0 - 0 \\
cov(\mathbf{x_1 x_2}, \mathbf{x_2}) &= 0 \\
cov(\mathbf{x_1 x_2}, \mathbf{z}) &= 0 \\
cov(\mathbf{x_1 z}, \mathbf{x1}) &= 0 \\
cov(\mathbf{x_1 z}, \mathbf{x2}) &= 0 \\
cov(\mathbf{x_1 z}, \mathbf{z}) &= 0 \\
\end{align*}
Where we make use of the fact that the expectation of the product of an odd number of standard normal variables equals 0. In the simplest case, $E(\mathbf{x_1}) =  E(\mathbf{x_2}) = E(\mathbf{z}) = 0$.
As a result,

\begin{equation*}
\frac{cov(\widetilde{\mathbf{x_1 x_2}}, \widetilde{\mathbf{x_1 z}})}{var(\widetilde{\mathbf{x_1 z}})} =
\frac{cov(\mathbf{x_1 x_2}, \mathbf{x_1 z})}{var(\mathbf{x_1 z})} 
\end{equation*}
where 

\begin{align*}
cov(\mathbf{x_1 x_2}, \mathbf{x_1 z}) &= E(\mathbf{x_1}^2 \mathbf{x_2 z }) - E(\mathbf{x_1 x_2}) E(\mathbf{x_1 z}) \\
&= E(\mathbf{x_1}^2) E(\mathbf{x_2 z }) + E(\mathbf{x_1 x_2}) E(\mathbf{x_1 z}) + E(\mathbf{x_1 z}) E(\mathbf{x_1 x_2}) - E(\mathbf{x_1 x_2}) E(\mathbf{x_1 z}) \\
&= E(\mathbf{x_1}^2) E(\mathbf{x_2 z }) + E(\mathbf{x_1 x_2}) E(\mathbf{x_1 z}) \\
&= r_{2z} + r_{12} r_{1z}
\end{align*}
In the last line we make use of the fact that E($\mathbf{x_1^2}) = var(\mathbf{x_1}) = 1$.

\begin{align*}
	var(\mathbf{x_1 z}) &= E(\mathbf{x_1^2 z^2}) - E(\mathbf{x_1 z}) E(\mathbf{x_1 z}) \\
	&= E(\mathbf{x^1}) E(\mathbf{z}) +  E(\mathbf{x_1 z}) E(\mathbf{x_1 z}) + E(\mathbf{x_1 z}) E(\mathbf{x_1 z}) - E(\mathbf{x_1 z}) E(\mathbf{x_1 z}) \\
	&= 1 + r^2_{1z}
\end{align*}
Putting it all together the bias of omitting the term $\mathbf{x_1 z}$ on the estimate of $\beta^{p3}_{12}$ is  $\gamma_1 \frac{r_{2z} + r_{12} r_{1z}}{1 + r^2_{1z}}$

Similarly, the bias of omitting the term $\mathbf{x_1 z}$ on the estimate of $\beta^{p3}_{12}$ is  $\gamma_2 \frac{r_{1z} + r_{12} r_{2z}}{1 + r_{2z}^2}$

The bias of omitting the terms $\mathbf{x_1^2}$ and $\mathbf{x_2^2}$ is respectively $\delta_1 r_{12}$ and $\delta_2 r_{12}$

\newpage
\section{R Functions Nearly Exact Correction} \label{appendix-R}
\begin{lstlisting}[language=R]
#' Install the sandwich package if necessary
if (!require("sandwich")) install.packages("sandwich")

#' Calculate the nearly exact bias and edf for the HC1 Variance
#' Estimator.
#' @param x design matrix of the regression
#' @param w hypothesis test
nearly_exact <- function(x, w){
  N = nrow(x); k = ncol(x) - 1; c = N / (N - k);
  xx <- solve(crossprod(x))
  M = diag(rep(1, N)) - tcrossprod(x %*% xx, x)
  z = tcrossprod(t(w) %*% xx, x); zz = z %*% t(z); z2 = z^2;
  mu = c/zz * sum(z^2 * diag(M))
  nu = 2 * c^2 / zz^2 * (tcrossprod(z2 %*% M^2, z2))
  edf = 2 * mu^2 / nu
  return(list(mu = as.numeric(mu), edf = as.numeric(edf)))
}

#' Calculate the coefficient table for the nearly
#' exact bias and df correction.
#' @param formula The regression formula as would be used with lm
#' @param data A dataframe
#' @param pdigits Number of digits to round the p-value

lm_nearly <- function(formula, data, pdigits = 4){
  reg <- lm(formula = formula, data = data)
  x <- model.matrix(object = formula, data = data)
  covHC <- sandwich::vcovHC(x = reg, type = "HC1")
  seHC <- sqrt(diag(covHC)); varnames <- names(seHC); 
  coefficients <- data.frame(matrix(nrow = length(varnames), ncol = 6))
  names(coefficients) <- c("variable", "estimate", "se",
                           "t value", "df", "p value")
  coefficients$variable <- varnames
  for (var in varnames){
    hypothesis = I(varnames == var)
    correction <- nearly_exact(x = x, w = hypothesis)
    se = seHC[var] / sqrt(correction$mu)
    stat <- reg$coefficients[var]/se
    coefficients[coefficients$variable == var, 2:6] <- c(
      reg$coefficients[var], se, stat, correction$edf, 
      round(2 * pt(abs(stat), correction$edf, lower.tail = FALSE),
            pdigits)
    )
  }
  return(list(coefficients = coefficients, lm = reg))
}

#' Useage

corrected <- lm_nearly(speed ~ dist, cars)
print(corrected$coefficients, digits = 2)
\end{lstlisting}

% \subsection{Quotes}
% 
% 
% \begin{quote}
% Which {[}specification{]} to use is both a theoretical (assumption of agents as perfectly or boundedly rational) and an empirical (market imperfections, exogenous shocks, experimentation, etc) issue because the likelihood of finding evidence of the former depends on the latter and vice versa (Grabner and Moers, 2013; Gerdin and Greve, 2004). (in Johansson, 2016).
% \end{quote}
% 
% \begin{quote}
% decision makers may not have been sufficiently well informed such that they chose efficiency or output enhancing combinations of practices.
% \citep{carree_note_2011}
% \end{quote}
% 
% Others have argued that the performance specification can be applied ``as long a the populaetion of organizations includes a reasonable number of organizations that takes non-optimal combinations of practice'' \citep{carree_note_2011}.
% 
% About the conditional correlation approach.
% \begin{quote}
% While this approach certainly has intuitive appeal and is easy to implement, it also relies on a strong assumption that the set of conditioning variables is reasonably complete. Without a well-specified reduced form regression, the correlation between the residual (p. 459) terms might not signal complementarity but rather the presence of a third factor that is correlated with the two organizational design choices under consideration. from (Hoffman and van Lent).
% \end{quote}
% 
% \begin{quote}
% This focus is appropriate as the control problems examined in this study (i.e. the alignment of behaviours to the strategic objectives of the firm) are complex and require significant experimentation by top management, particularly in conditions characterized by uncertainty such as the prospector strategic context (Simons, 1995). Hence it is unlikely that firms will be, on average, in an optimal equilibrium. in \citep{bedford_management_2016}
% \end{quote}
% 
\newpage

\bibliographystyle{model5-names.bst}
\bibliography{references2.bib}

\end{document}
